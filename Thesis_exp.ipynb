{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "n26igyz9T56e",
   "metadata": {
    "id": "n26igyz9T56e"
   },
   "source": [
    "Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "005d60ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "005d60ee",
    "outputId": "b66291f4-62bc-4713-b8c9-8753c0b6748f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\h.ahmed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os \n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC  # For SVM classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "OnFoKi8s8n3h",
   "metadata": {
    "id": "OnFoKi8s8n3h"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oUWLoWzxUsVZ",
   "metadata": {
    "id": "oUWLoWzxUsVZ"
   },
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ec312c6",
   "metadata": {
    "id": "8ec312c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\h.ahmed\\AppData\\Local\\Temp\\ipykernel_4216\\3640496504.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  dataset = pd.read_csv(\"C:\\data\\RomanUrduDataset_WIP.csv\", usecols = [0,1], names = ['Sentence','Catagories'], encoding='ISO-8859-1')\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:\\data\\RomanUrduDataset_WIP.csv\", usecols = [0,1], names = ['Sentence','Catagories'], encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de83dd6c",
   "metadata": {
    "id": "de83dd6c"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "905c46dc",
   "metadata": {
    "id": "905c46dc"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d634f0ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d634f0ba",
    "outputId": "56e0b758-7f2b-48df-9ac0-b7b3d4e312dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catagories\n",
       "religious offensive    200\n",
       "political offensive    200\n",
       "Neutral                200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Catagories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2fb6e73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2fb6e73",
    "outputId": "02fca4f8-1605-4f33-fd8d-017974e91379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WeIek45pU2Gc",
   "metadata": {
    "id": "WeIek45pU2Gc"
   },
   "source": [
    "Data Pre-processing (Removing Punctuation, digits, special characters, white spaces, checking duplicates, converting to lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ipDTLc_C88Fx",
   "metadata": {
    "id": "ipDTLc_C88Fx"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(sentence):\n",
    "    # Convert each sentence to lowercase\n",
    "    sentence = sentence.str.lower()\n",
    "     # Remove non-ASCII characters\n",
    "    sentence = sentence.str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    # Remove dots, punctuations, digits, and special characters\n",
    "    sentence = sentence.str.replace(r'[^\\w\\s]', '')\n",
    "    # Remove emoticons like :) :D :p :o\n",
    "    sentence = sentence.str.replace(r'[:;][\\)\\(dpo*]', '')\n",
    "    sentence = sentence.str.replace(r'([^\\w\\s]|_)+(?=\\s|$)', '')\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^\\W.*', '', word) for word in x.split()]))\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^\\W+|\\W+$', '', word) for word in x.split()]))\n",
    "    # sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^[^\\w\\s]+|[^\\w\\s]+$', '', word) for word in x.split()]))\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'([^\\w\\s]|_)+(?=\\s|$)', '', word) for word in x.split()]))\n",
    "\n",
    "    # Remove specific special characters like question marks\n",
    "    sentence = sentence.str.replace(r'\\?+', '')\n",
    "    # Remove big words with length more than 10 characters\n",
    "    sentence = sentence.apply(lambda x: ' '.join([word for word in x.split() if len(word) <= 10]))\n",
    "    # Remove duplicate words in each sentence\n",
    "    sentence = sentence.apply(lambda x: ' '.join(sorted(set(x.split()), key=x.split().index)))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cca52735",
   "metadata": {
    "id": "cca52735"
   },
   "outputs": [],
   "source": [
    "# def data_preprocessing(ru_text):\n",
    "#     ru_text = ru_text.astype(str).str.lower()\n",
    "#     ru_text = ru_text.astype(str).str.replace('[{}]'.format(string.punctuation), '')\n",
    "#     ru_text = ru_text.astype(str).str.replace(\"[^a-zA-Z#]\",' ')\n",
    "#     ru_text = ru_text.apply(lambda x: ' '.join([word for word in str(x).split() if not word.isdigit()]))\n",
    "#     ru_text = ru_text.astype(str).str.strip()\n",
    "#     return ru_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae923c2e",
   "metadata": {
    "id": "ae923c2e"
   },
   "outputs": [],
   "source": [
    "dataset.replace('', np.nan, inplace = True)\n",
    "dataset.dropna(inplace=True)\n",
    "dataset['Sentence'] = data_preprocessing(dataset['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "KDAdr-rF7jdU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "KDAdr-rF7jdU",
    "outputId": "b3c9664a-a28a-4656-87c0-da4b8333320d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive\n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive\n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive\n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive\n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive\n",
       "..                                                 ...                  ...\n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral\n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral\n",
       "598                              g m asaa kuch nh khti              Neutral\n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral\n",
       "600                               main apka btaou janu              Neutral\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "WV79B3N0DfFc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "WV79B3N0DfFc",
    "outputId": "72f11e64-4481-4467-d5f9-332f758cfc02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "dataset.groupby('Catagories').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f67007bb",
   "metadata": {
    "id": "f67007bb"
   },
   "outputs": [],
   "source": [
    "#sent = dataset[\"Sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ad12a0b",
   "metadata": {
    "id": "1ad12a0b"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['Sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzTGDORTW478",
   "metadata": {
    "id": "tzTGDORTW478"
   },
   "source": [
    "Data Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67b288aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "67b288aa",
    "outputId": "e9553272-0ef8-42f2-97cd-259d682f5538"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ecbf4b9",
   "metadata": {
    "id": "7ecbf4b9"
   },
   "outputs": [],
   "source": [
    "with open (\"C:/data/ru_words.json\") as f:\n",
    "    ru_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7e9ffe7",
   "metadata": {
    "id": "d7e9ffe7"
   },
   "outputs": [],
   "source": [
    "def Lema(variations,token_sent):\n",
    "  sents = token_sent.copy()\n",
    "  lematized = []\n",
    "  replacements = variations.keys()\n",
    "  for i,tokens in enumerate(sents):\n",
    "    for j,token in enumerate(tokens):\n",
    "      if token in replacements:\n",
    "        #print(f\"Original  {token} with {variations[token]} on index {i}\")\n",
    "        tokens[j] = variations[token]\n",
    "    #print(tokens)\n",
    "    lematized.append(tokens)\n",
    "  return lematized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "iQxYzt-8HMbE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQxYzt-8HMbE",
    "outputId": "678e1a1a-aa8a-4457-9cc8-978c4a941498"
   },
   "outputs": [],
   "source": [
    "token_sent = Lema(ru_words[\"ru_words\"],dataset[\"lematized_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0xRim3JCshc",
   "metadata": {
    "id": "f0xRim3JCshc"
   },
   "outputs": [],
   "source": [
    "dataset['tokenized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['Sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "-D_CawTdFoz4",
   "metadata": {
    "id": "-D_CawTdFoz4"
   },
   "outputs": [],
   "source": [
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5sQEAEIJRCWE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5sQEAEIJRCWE",
    "outputId": "3fa7ef62-d399-4e73-b643-90e02f74e59e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sare, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nahi, khti]</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...   \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]   \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...   \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...   \n",
       "5    [sare, shia, jahil, hain, in, ky, belief, ki, ...   \n",
       "..                                                 ...   \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...   \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...   \n",
       "598                     [g, m, asaa, kuch, nahi, khti]   \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...   \n",
       "600                          [main, apka, btaou, janu]   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "qJl0yK7DMqCl",
   "metadata": {
    "id": "qJl0yK7DMqCl"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset['lematized_sent'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "gwlkObzGMxtA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gwlkObzGMxtA",
    "outputId": "30ec570c-ae6c-44f9-9a8a-a7206807e366"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>sare shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g m asaa kuch nahi khti</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...   \n",
       "2                       qadyani ka jo yaar hai ghaddar   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...   \n",
       "5           sare shia jahil hain in ky belief ki tarha   \n",
       "..                                                 ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...   \n",
       "598                            g m asaa kuch nahi khti   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy   \n",
       "600                               main apka btaou janu   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPUALPkNPqH4",
   "metadata": {
    "id": "LPUALPkNPqH4"
   },
   "source": [
    "Saving Dataset for Target Group Identification (task 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "s0_EkIQPP3qT",
   "metadata": {
    "id": "s0_EkIQPP3qT"
   },
   "outputs": [],
   "source": [
    "copy_data = dataset[['lematized_sent','Catagories']]\n",
    "copy_data.to_csv(r'C:\\results\\task_02_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "C-paFIc9QyHE",
   "metadata": {
    "id": "C-paFIc9QyHE"
   },
   "outputs": [],
   "source": [
    "# read_back_data = pd.read_csv(('/content/drive/MyDrive/Thesis_Data/Group_identification_data.csv'),index_col=0)\n",
    "# read_back_data\n",
    "# read_back_data = copy_data.copy()\n",
    "# read_back_data = read_back_data.set_index(read_back_data.columns[0])\n",
    "# read_back_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nJ2Ezv7XGeS",
   "metadata": {
    "id": "0nJ2Ezv7XGeS"
   },
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "jRjUfQhpM7rv",
   "metadata": {
    "id": "jRjUfQhpM7rv"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['lematized_sent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "_rxpjeMANd4u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_rxpjeMANd4u",
    "outputId": "28db72c4-6ad0-4fdf-c2b2-b4dcfe96a084"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sare, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nahi, khti]</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...   \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]   \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...   \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...   \n",
       "5    [sare, shia, jahil, hain, in, ky, belief, ki, ...   \n",
       "..                                                 ...   \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...   \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...   \n",
       "598                     [g, m, asaa, kuch, nahi, khti]   \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...   \n",
       "600                          [main, apka, btaou, janu]   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "YIM-LBy0J_iq",
   "metadata": {
    "id": "YIM-LBy0J_iq"
   },
   "outputs": [],
   "source": [
    "ru_stopwords =  ['ai', 'ayi', 'hy', 'hai', 'main', 'ki', 'tha', 'koi', 'ko', 'sy', 'woh ', 'bhi',\n",
    "                 'aur', 'wo', 'yeh', 'rha', 'hota', 'ho', 'ga', 'ka', 'le', 'lye ', 'kr', 'kar',\n",
    "                 'lye', 'liye', 'hotay', 'waisay', 'gya', 'gaya', 'kch', 'ab', 'thy', 'thay', 'houn',\n",
    "                 'hain', 'han', 'to', 'is', 'hi', 'jo', 'kya', 'thi', 'se', 'pe', 'phr', 'wala', 'waisay',\n",
    "                 'us', 'na', 'ny', 'hun', 'rha', 'raha', 'ja', 'rahay', 'abi', 'uski', 'ne', 'haan', 'acha',\n",
    "                 'nai', 'sent', 'you', 'kafi', 'gai', 'rhy', 'kuch', 'jata', 'aye', 'ya', 'dono', 'hoa',\n",
    "                 'aese', 'de', 'wohi', 'jati', 'jb', 'krta', 'lg', 'rahi', 'hui', 'karna', 'krna', 'gi', 'hova',\n",
    "                 'yehi', 'jana', 'jye', 'chal', 'mil', 'tu', 'hum', 'par', 'hay', 'kis', 'sb', 'gy', 'dain', 'krny', 'tou',\n",
    "                 'hn', 'rahe','karo','kro','kia','don','kha', 'aap','aby','agya','ap','app','aray','ary','ata','atay','ati','bd',\n",
    "\t\t\t\t         'bna','da','di','ek','esa','ge','ha','hmy','hon','hoti','hoty','hue','hue','huy','iss','jay','jaye','je','ji',\n",
    "                 'karta','karte','karty','ky','liya','mn','mlti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "hYSuA5CeLVq2",
   "metadata": {
    "id": "hYSuA5CeLVq2"
   },
   "outputs": [],
   "source": [
    "def stopwords_removal(ru_text):\n",
    "  ru_text = ru_text.apply(lambda x: ' '.join([word for word in str(x).split() if not word in ru_stopwords]))\n",
    "  return ru_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cIUE2sjoL--F",
   "metadata": {
    "id": "cIUE2sjoL--F"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = stopwords_removal(dataset['lematized_sent'].str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "p1puuXKDZoz-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "p1puuXKDZoz-",
    "outputId": "d3542625-267b-48ea-b8c1-113349b60db1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aj shia mila mene pocha k tum log zuljana tatt...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>qadyani yaar ghaddar</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>jaa khatmal tum sare mutah paidawar</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>mirza qadyani zaryat ke kafir honay mein shak ...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>sare shia jahil in belief tarha</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai ye sun matlb me bilkul thek kehta</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai dunya gol kisi tariqe ye bat samne ani</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g m asaa nahi khti</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g apne friday e ye alfaz milahaza fermae</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>apka btaou janu</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    aj shia mila mene pocha k tum log zuljana tatt...   \n",
       "2                                 qadyani yaar ghaddar   \n",
       "3                  jaa khatmal tum sare mutah paidawar   \n",
       "4    mirza qadyani zaryat ke kafir honay mein shak ...   \n",
       "5                      sare shia jahil in belief tarha   \n",
       "..                                                 ...   \n",
       "596             bhai ye sun matlb me bilkul thek kehta   \n",
       "597        bhai dunya gol kisi tariqe ye bat samne ani   \n",
       "598                                 g m asaa nahi khti   \n",
       "599           g apne friday e ye alfaz milahaza fermae   \n",
       "600                                    apka btaou janu   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "Aizy1p4PMdO2",
   "metadata": {
    "id": "Aizy1p4PMdO2"
   },
   "outputs": [],
   "source": [
    "temp_data = dataset[['lematized_sent','Catagories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Z2Q2Rf9Mc2B",
   "metadata": {
    "id": "5Z2Q2Rf9Mc2B"
   },
   "source": [
    "Spliting dataset traning 80% testing 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ja98kGAHMDZz",
   "metadata": {
    "id": "ja98kGAHMDZz"
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "X = temp_data['lematized_sent']\n",
    "y = labelencoder.fit_transform(temp_data['Catagories'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2V_oeelwPnRe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V_oeelwPnRe",
    "outputId": "ab10d61b-bece-4845-eed8-7255ff657d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'religious offensive', 1: 'political offensive', 0: 'Neutral'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = list(set([categories for _, categories in enumerate(zip(temp_data['Catagories'], y.tolist()))]))\n",
    "# categories = dict(categories)\n",
    "categories = dict([(index, category) for category, index in categories])\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFMh4hsGLjog",
   "metadata": {
    "id": "XFMh4hsGLjog"
   },
   "source": [
    "Initialze N-gram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "X5NxC9iUC3sE",
   "metadata": {
    "id": "X5NxC9iUC3sE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer_uni = TfidfVectorizer()\n",
    "\n",
    "vectorizer_uni.fit(X_train)\n",
    "\n",
    "X_train_uni, X_test_uni = vectorizer_uni.transform(X_train), vectorizer_uni.transform(X_test)\n",
    "\n",
    "print(type(vectorizer_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7m_1rZvqOK0",
   "metadata": {
    "id": "I7m_1rZvqOK0"
   },
   "source": [
    "Testing Feature selection (Mutual Info & Chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "SzGkWoMraaeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzGkWoMraaeq",
    "outputId": "ce6c3ddf-bff3-4a19-cb94-bf3793ce3690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 1610), (120,), (120,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_uni.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "DCWm9-MFCr7U",
   "metadata": {
    "id": "DCWm9-MFCr7U"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def select_features(selection_method, k, X_train, y_train, X_test):\n",
    "    \"\"\"Applies feature selection and returns the selector along with transformed training and testing data.\"\"\"\n",
    "    selector = SelectKBest(selection_method, k=k)\n",
    "    X_train_transformed = selector.fit_transform(X_train, y_train)\n",
    "    X_test_transformed = selector.transform(X_test)\n",
    "    return selector, X_train_transformed, X_test_transformed\n",
    "\n",
    "# Define number of features for different selections\n",
    "feature_numbers = [400, 800, 1200]\n",
    "\n",
    "# Initialize a dictionary to store training and testing datasets\n",
    "train_set = {}\n",
    "\n",
    "\n",
    "# Apply feature selection for Chi-square\n",
    "for k in feature_numbers:\n",
    "    selector_chi, X_train_chi, X_test_chi = select_features(chi2, k, X_train_uni, y_train, X_test_uni)\n",
    "    train_set[f\"chi2_{k}\"] = {\n",
    "        \"selector\": selector_chi,\n",
    "        \"train\": X_train_chi,\n",
    "        \"test\": X_test_chi\n",
    "    }\n",
    "\n",
    "# Apply feature selection for Mutual Information\n",
    "for k in feature_numbers:\n",
    "    selector_mi, X_train_mi, X_test_mi = select_features(mutual_info_classif, k, X_train_uni, y_train, X_test_uni)\n",
    "    train_set[f\"mi_{k}\"] = {\n",
    "        \"selector\": selector_mi,\n",
    "        \"train\": X_train_mi,\n",
    "        \"test\": X_test_mi\n",
    "    }\n",
    "\n",
    "# Include unfiltered features as well\n",
    "# Assuming there is a basic selector or process for 'uni' that you might want to keep track of (even if it's just identity)\n",
    "train_set[\"uni\"] = {\n",
    "    \"selector\": vectorizer_uni,  # or an identity/select-all selector if applicable\n",
    "    \"train\": X_train_uni,\n",
    "    \"test\": X_test_uni\n",
    "}\n",
    "\n",
    "### Saving the selctors###\n",
    "base_path = \"C:\\\\Results\\\\Selectors\"\n",
    "# Ensure the directory exists; if not, create it\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "for key, value in train_set.items():\n",
    "    if value[\"selector\"] is not None:\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(base_path, f'selector_{key}.pkl')\n",
    "        \n",
    "        # Save the selector to the file\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(value[\"selector\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1f4670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_400\n",
      "  (0, 388)\t0.3431510931988059\n",
      "  (0, 308)\t0.345788434434944\n",
      "  (0, 266)\t0.5182577064957191\n",
      "  (0, 200)\t0.49056631238126797\n",
      "  (0, 192)\t0.503419634760044\n",
      "  (1, 329)\t0.3892813329205754\n",
      "  (1, 209)\t0.2283544531051882\n",
      "  (1, 199)\t0.3264538688523205\n",
      "  (2, 388)\t0.24143344129228228\n",
      "  (2, 377)\t0.34515149544243506\n",
      "  (2, 306)\t0.33717473034061024\n",
      "  (2, 228)\t0.3920943527860786\n",
      "  (2, 197)\t0.41157739890698797\n",
      "  (2, 104)\t0.3920943527860786\n",
      "  (3, 305)\t0.6439696849245412\n",
      "  (3, 270)\t0.7650510080368413\n",
      "  (4, 258)\t0.25019636316941485\n",
      "  (4, 27)\t0.3059275437717956\n",
      "  (4, 24)\t0.34531249337969183\n",
      "  (5, 369)\t0.43286842010469856\n",
      "  (5, 221)\t0.4805704809666063\n",
      "  (5, 85)\t0.7626774834093286\n",
      "  (6, 368)\t0.6213933333379952\n",
      "  (6, 212)\t0.6213933333379952\n",
      "  (6, 32)\t0.4772218043700333\n",
      "  :\t:\n",
      "  (470, 342)\t0.29843917921162844\n",
      "  (470, 269)\t0.30625858075643553\n",
      "  (470, 263)\t0.17142259141095437\n",
      "  (470, 183)\t0.32596189901822253\n",
      "  (471, 334)\t0.2484417152719478\n",
      "  (472, 301)\t0.5978718910411236\n",
      "  (472, 140)\t0.5978718910411236\n",
      "  (473, 276)\t0.351390987964331\n",
      "  (473, 258)\t0.25460053987248443\n",
      "  (473, 207)\t0.351390987964331\n",
      "  (473, 154)\t0.25460053987248443\n",
      "  (474, 266)\t0.4712993777711736\n",
      "  (474, 256)\t0.5674667108206044\n",
      "  (474, 200)\t0.44611704733560104\n",
      "  (474, 97)\t0.5067918790781026\n",
      "  (475, 308)\t0.416567333480062\n",
      "  (475, 209)\t0.4133901589513351\n",
      "  (475, 153)\t0.7047161546645925\n",
      "  (477, 220)\t0.327742620382574\n",
      "  (477, 202)\t0.35443427214502454\n",
      "  (477, 163)\t0.38112592390747496\n",
      "  (478, 151)\t0.22159366283615334\n",
      "  (478, 60)\t0.17769345715437915\n",
      "  (478, 11)\t0.18153519534937598\n",
      "  (478, 3)\t0.17769345715437915\n",
      "chi2_800\n",
      "  (0, 783)\t0.3431510931988059\n",
      "  (0, 623)\t0.345788434434944\n",
      "  (0, 537)\t0.5182577064957191\n",
      "  (0, 406)\t0.49056631238126797\n",
      "  (0, 398)\t0.503419634760044\n",
      "  (1, 787)\t0.4152535849026359\n",
      "  (1, 664)\t0.3892813329205754\n",
      "  (1, 424)\t0.2283544531051882\n",
      "  (1, 405)\t0.3264538688523205\n",
      "  (1, 302)\t0.4152535849026359\n",
      "  (1, 98)\t0.4152535849026359\n",
      "  (1, 82)\t0.4152535849026359\n",
      "  (2, 783)\t0.24143344129228228\n",
      "  (2, 764)\t0.34515149544243506\n",
      "  (2, 620)\t0.33717473034061024\n",
      "  (2, 572)\t0.27979213728786234\n",
      "  (2, 460)\t0.3920943527860786\n",
      "  (2, 403)\t0.41157739890698797\n",
      "  (2, 222)\t0.3920943527860786\n",
      "  (3, 619)\t0.6439696849245412\n",
      "  (3, 547)\t0.7650510080368413\n",
      "  (4, 523)\t0.25019636316941485\n",
      "  (4, 294)\t0.25019636316941485\n",
      "  (4, 61)\t0.3059275437717956\n",
      "  (4, 47)\t0.34531249337969183\n",
      "  :\t:\n",
      "  (474, 537)\t0.4712993777711736\n",
      "  (474, 518)\t0.5674667108206044\n",
      "  (474, 406)\t0.44611704733560104\n",
      "  (474, 206)\t0.5067918790781026\n",
      "  (475, 623)\t0.416567333480062\n",
      "  (475, 424)\t0.4133901589513351\n",
      "  (475, 314)\t0.7047161546645925\n",
      "  (476, 528)\t0.5013203295453942\n",
      "  (476, 235)\t0.5013203295453942\n",
      "  (476, 144)\t0.5013203295453942\n",
      "  (477, 739)\t0.3664364479313411\n",
      "  (477, 448)\t0.327742620382574\n",
      "  (477, 412)\t0.35443427214502454\n",
      "  (477, 342)\t0.38112592390747496\n",
      "  (477, 34)\t0.42675560398020507\n",
      "  (478, 515)\t0.22159366283615334\n",
      "  (478, 311)\t0.22159366283615334\n",
      "  (478, 124)\t0.17769345715437915\n",
      "  (478, 33)\t0.20296753617426183\n",
      "  (478, 27)\t0.18153519534937598\n",
      "  (478, 13)\t0.17769345715437915\n",
      "  (479, 616)\t0.4504780401896615\n",
      "  (479, 324)\t0.4504780401896615\n",
      "  (479, 26)\t0.40231190326741934\n",
      "  (479, 18)\t0.4504780401896615\n",
      "chi2_1200\n",
      "  (0, 1170)\t0.3431510931988059\n",
      "  (0, 934)\t0.345788434434944\n",
      "  (0, 818)\t0.5182577064957191\n",
      "  (0, 607)\t0.49056631238126797\n",
      "  (0, 594)\t0.503419634760044\n",
      "  (1, 1180)\t0.4152535849026359\n",
      "  (1, 999)\t0.3892813329205754\n",
      "  (1, 639)\t0.2283544531051882\n",
      "  (1, 605)\t0.3264538688523205\n",
      "  (1, 465)\t0.4152535849026359\n",
      "  (1, 145)\t0.4152535849026359\n",
      "  (1, 123)\t0.4152535849026359\n",
      "  (2, 1170)\t0.24143344129228228\n",
      "  (2, 1149)\t0.34515149544243506\n",
      "  (2, 929)\t0.33717473034061024\n",
      "  (2, 865)\t0.27979213728786234\n",
      "  (2, 699)\t0.3920943527860786\n",
      "  (2, 603)\t0.41157739890698797\n",
      "  (2, 338)\t0.3920943527860786\n",
      "  (3, 928)\t0.6439696849245412\n",
      "  (3, 830)\t0.7650510080368413\n",
      "  (4, 1148)\t0.3683512119931035\n",
      "  (4, 911)\t0.3683512119931035\n",
      "  (4, 843)\t0.3683512119931035\n",
      "  (4, 794)\t0.25019636316941485\n",
      "  :\t:\n",
      "  (474, 786)\t0.5674667108206044\n",
      "  (474, 607)\t0.44611704733560104\n",
      "  (474, 316)\t0.5067918790781026\n",
      "  (475, 934)\t0.416567333480062\n",
      "  (475, 639)\t0.4133901589513351\n",
      "  (475, 479)\t0.7047161546645925\n",
      "  (476, 803)\t0.5013203295453942\n",
      "  (476, 361)\t0.5013203295453942\n",
      "  (476, 228)\t0.5013203295453942\n",
      "  (477, 1111)\t0.3664364479313411\n",
      "  (477, 680)\t0.327742620382574\n",
      "  (477, 641)\t0.38112592390747496\n",
      "  (477, 615)\t0.35443427214502454\n",
      "  (477, 515)\t0.38112592390747496\n",
      "  (477, 48)\t0.42675560398020507\n",
      "  (478, 783)\t0.22159366283615334\n",
      "  (478, 476)\t0.22159366283615334\n",
      "  (478, 186)\t0.17769345715437915\n",
      "  (478, 46)\t0.20296753617426183\n",
      "  (478, 40)\t0.18153519534937598\n",
      "  (478, 22)\t0.17769345715437915\n",
      "  (479, 925)\t0.4504780401896615\n",
      "  (479, 489)\t0.4504780401896615\n",
      "  (479, 39)\t0.40231190326741934\n",
      "  (479, 27)\t0.4504780401896615\n",
      "mi_400\n",
      "  (0, 390)\t0.3431510931988059\n",
      "  (0, 307)\t0.345788434434944\n",
      "  (0, 267)\t0.5182577064957191\n",
      "  (0, 192)\t0.49056631238126797\n",
      "  (0, 187)\t0.503419634760044\n",
      "  (1, 324)\t0.3892813329205754\n",
      "  (1, 207)\t0.2283544531051882\n",
      "  (1, 191)\t0.3264538688523205\n",
      "  (2, 390)\t0.24143344129228228\n",
      "  (2, 381)\t0.34515149544243506\n",
      "  (2, 305)\t0.33717473034061024\n",
      "  (2, 283)\t0.27979213728786234\n",
      "  (2, 225)\t0.3920943527860786\n",
      "  (2, 122)\t0.3920943527860786\n",
      "  (2, 106)\t0.3920943527860786\n",
      "  (3, 304)\t0.6439696849245412\n",
      "  (3, 271)\t0.7650510080368413\n",
      "  (4, 261)\t0.25019636316941485\n",
      "  (4, 145)\t0.34531249337969183\n",
      "  (4, 142)\t0.25019636316941485\n",
      "  (4, 33)\t0.3059275437717956\n",
      "  (4, 24)\t0.34531249337969183\n",
      "  (5, 372)\t0.43286842010469856\n",
      "  (5, 217)\t0.4805704809666063\n",
      "  (6, 40)\t0.4772218043700333\n",
      "  :\t:\n",
      "  (475, 207)\t0.4133901589513351\n",
      "  (475, 179)\t0.39869207982382987\n",
      "  (475, 156)\t0.7047161546645925\n",
      "  (476, 240)\t0.24644737483343024\n",
      "  (476, 134)\t0.4304619297814882\n",
      "  (477, 370)\t0.3664364479313411\n",
      "  (477, 216)\t0.327742620382574\n",
      "  (477, 208)\t0.38112592390747496\n",
      "  (477, 196)\t0.35443427214502454\n",
      "  (477, 166)\t0.38112592390747496\n",
      "  (477, 101)\t0.4000639522177546\n",
      "  (478, 347)\t0.22159366283615334\n",
      "  (478, 258)\t0.22159366283615334\n",
      "  (478, 240)\t0.11620264884271594\n",
      "  (478, 198)\t0.174218182229611\n",
      "  (478, 179)\t0.1253662736793302\n",
      "  (478, 154)\t0.22159366283615334\n",
      "  (478, 66)\t0.17769345715437915\n",
      "  (478, 16)\t0.20296753617426183\n",
      "  (478, 15)\t0.20296753617426183\n",
      "  (478, 13)\t0.18153519534937598\n",
      "  (478, 7)\t0.17769345715437915\n",
      "  (479, 306)\t0.33863973364771593\n",
      "  (479, 18)\t0.33863973364771593\n",
      "  (479, 11)\t0.40231190326741934\n",
      "mi_800\n",
      "  (0, 767)\t0.3431510931988059\n",
      "  (0, 606)\t0.345788434434944\n",
      "  (0, 534)\t0.5182577064957191\n",
      "  (0, 394)\t0.49056631238126797\n",
      "  (0, 385)\t0.503419634760044\n",
      "  (1, 776)\t0.4152535849026359\n",
      "  (1, 639)\t0.3892813329205754\n",
      "  (1, 423)\t0.2283544531051882\n",
      "  (1, 393)\t0.3264538688523205\n",
      "  (1, 290)\t0.4152535849026359\n",
      "  (1, 100)\t0.4152535849026359\n",
      "  (1, 88)\t0.4152535849026359\n",
      "  (2, 767)\t0.24143344129228228\n",
      "  (2, 746)\t0.34515149544243506\n",
      "  (2, 604)\t0.33717473034061024\n",
      "  (2, 563)\t0.27979213728786234\n",
      "  (2, 459)\t0.3920943527860786\n",
      "  (2, 391)\t0.41157739890698797\n",
      "  (2, 244)\t0.3920943527860786\n",
      "  (2, 208)\t0.3920943527860786\n",
      "  (3, 603)\t0.6439696849245412\n",
      "  (3, 542)\t0.7650510080368413\n",
      "  (4, 743)\t0.3683512119931035\n",
      "  (4, 594)\t0.3683512119931035\n",
      "  (4, 548)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (476, 220)\t0.5013203295453942\n",
      "  (476, 141)\t0.5013203295453942\n",
      "  (477, 716)\t0.3664364479313411\n",
      "  (477, 442)\t0.327742620382574\n",
      "  (477, 424)\t0.38112592390747496\n",
      "  (477, 402)\t0.35443427214502454\n",
      "  (477, 337)\t0.38112592390747496\n",
      "  (477, 196)\t0.4000639522177546\n",
      "  (478, 672)\t0.22159366283615334\n",
      "  (478, 511)\t0.22159366283615334\n",
      "  (478, 484)\t0.11620264884271594\n",
      "  (478, 405)\t0.174218182229611\n",
      "  (478, 364)\t0.1253662736793302\n",
      "  (478, 302)\t0.22159366283615334\n",
      "  (478, 122)\t0.17769345715437915\n",
      "  (478, 32)\t0.20296753617426183\n",
      "  (478, 31)\t0.20296753617426183\n",
      "  (478, 29)\t0.18153519534937598\n",
      "  (478, 15)\t0.17769345715437915\n",
      "  (479, 605)\t0.33863973364771593\n",
      "  (479, 601)\t0.4504780401896615\n",
      "  (479, 315)\t0.4504780401896615\n",
      "  (479, 34)\t0.33863973364771593\n",
      "  (479, 27)\t0.40231190326741934\n",
      "  (479, 19)\t0.4504780401896615\n",
      "mi_1200\n",
      "  (0, 1167)\t0.3431510931988059\n",
      "  (0, 925)\t0.345788434434944\n",
      "  (0, 821)\t0.5182577064957191\n",
      "  (0, 603)\t0.49056631238126797\n",
      "  (0, 591)\t0.503419634760044\n",
      "  (1, 1176)\t0.4152535849026359\n",
      "  (1, 975)\t0.3892813329205754\n",
      "  (1, 641)\t0.2283544531051882\n",
      "  (1, 602)\t0.3264538688523205\n",
      "  (1, 450)\t0.4152535849026359\n",
      "  (1, 146)\t0.4152535849026359\n",
      "  (1, 131)\t0.4152535849026359\n",
      "  (2, 1167)\t0.24143344129228228\n",
      "  (2, 1142)\t0.34515149544243506\n",
      "  (2, 919)\t0.33717473034061024\n",
      "  (2, 861)\t0.27979213728786234\n",
      "  (2, 699)\t0.3920943527860786\n",
      "  (2, 600)\t0.41157739890698797\n",
      "  (2, 384)\t0.3920943527860786\n",
      "  (2, 327)\t0.3920943527860786\n",
      "  (3, 918)\t0.6439696849245412\n",
      "  (3, 831)\t0.7650510080368413\n",
      "  (4, 1139)\t0.3683512119931035\n",
      "  (4, 904)\t0.3683512119931035\n",
      "  (4, 838)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (478, 1000)\t0.23637805130304798\n",
      "  (478, 885)\t0.23637805130304798\n",
      "  (478, 789)\t0.22159366283615334\n",
      "  (478, 744)\t0.11620264884271594\n",
      "  (478, 620)\t0.174218182229611\n",
      "  (478, 562)\t0.1253662736793302\n",
      "  (478, 467)\t0.22159366283615334\n",
      "  (478, 464)\t0.23637805130304798\n",
      "  (478, 355)\t0.23637805130304798\n",
      "  (478, 312)\t0.23637805130304798\n",
      "  (478, 255)\t0.23637805130304798\n",
      "  (478, 208)\t0.23637805130304798\n",
      "  (478, 189)\t0.23637805130304798\n",
      "  (478, 185)\t0.17769345715437915\n",
      "  (478, 51)\t0.20296753617426183\n",
      "  (478, 49)\t0.20296753617426183\n",
      "  (478, 43)\t0.18153519534937598\n",
      "  (478, 41)\t0.23637805130304798\n",
      "  (478, 21)\t0.17769345715437915\n",
      "  (479, 923)\t0.33863973364771593\n",
      "  (479, 915)\t0.4504780401896615\n",
      "  (479, 481)\t0.4504780401896615\n",
      "  (479, 53)\t0.33863973364771593\n",
      "  (479, 38)\t0.40231190326741934\n",
      "  (479, 27)\t0.4504780401896615\n",
      "uni\n",
      "  (0, 1573)\t0.3431510931988059\n",
      "  (0, 1236)\t0.345788434434944\n",
      "  (0, 1091)\t0.5182577064957191\n",
      "  (0, 800)\t0.49056631238126797\n",
      "  (0, 785)\t0.503419634760044\n",
      "  (1, 1583)\t0.4152535849026359\n",
      "  (1, 1318)\t0.3892813329205754\n",
      "  (1, 845)\t0.2283544531051882\n",
      "  (1, 798)\t0.3264538688523205\n",
      "  (1, 620)\t0.4152535849026359\n",
      "  (1, 198)\t0.4152535849026359\n",
      "  (1, 173)\t0.4152535849026359\n",
      "  (2, 1573)\t0.24143344129228228\n",
      "  (2, 1546)\t0.34515149544243506\n",
      "  (2, 1225)\t0.33717473034061024\n",
      "  (2, 1145)\t0.27979213728786234\n",
      "  (2, 926)\t0.3920943527860786\n",
      "  (2, 795)\t0.41157739890698797\n",
      "  (2, 532)\t0.3920943527860786\n",
      "  (2, 460)\t0.3920943527860786\n",
      "  (3, 1224)\t0.6439696849245412\n",
      "  (3, 1104)\t0.7650510080368413\n",
      "  (4, 1542)\t0.3683512119931035\n",
      "  (4, 1206)\t0.3683512119931035\n",
      "  (4, 1118)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (478, 1349)\t0.23637805130304798\n",
      "  (478, 1177)\t0.23637805130304798\n",
      "  (478, 1045)\t0.22159366283615334\n",
      "  (478, 988)\t0.11620264884271594\n",
      "  (478, 820)\t0.174218182229611\n",
      "  (478, 752)\t0.1253662736793302\n",
      "  (478, 639)\t0.22159366283615334\n",
      "  (478, 636)\t0.23637805130304798\n",
      "  (478, 497)\t0.23637805130304798\n",
      "  (478, 440)\t0.23637805130304798\n",
      "  (478, 363)\t0.23637805130304798\n",
      "  (478, 291)\t0.23637805130304798\n",
      "  (478, 260)\t0.23637805130304798\n",
      "  (478, 254)\t0.17769345715437915\n",
      "  (478, 70)\t0.20296753617426183\n",
      "  (478, 68)\t0.20296753617426183\n",
      "  (478, 62)\t0.18153519534937598\n",
      "  (478, 60)\t0.23637805130304798\n",
      "  (478, 38)\t0.17769345715437915\n",
      "  (479, 1233)\t0.33863973364771593\n",
      "  (479, 1221)\t0.4504780401896615\n",
      "  (479, 656)\t0.4504780401896615\n",
      "  (479, 72)\t0.33863973364771593\n",
      "  (479, 57)\t0.40231190326741934\n",
      "  (479, 44)\t0.4504780401896615\n"
     ]
    }
   ],
   "source": [
    "for i, train_set_key in enumerate(train_set):\n",
    "         x_train=train_set.get(train_set_key)[\"train\"]\n",
    "         print(train_set_key)\n",
    "         print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aqT6lsq_4BEX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqT6lsq_4BEX",
    "outputId": "7a3c0436-0ad6-405e-8718-7069aa053ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UniGram features after TF-IDF transformation: 1610\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer_uni.get_feature_names_out()\n",
    "num_features = len(feature_names)\n",
    "\n",
    "print(f\"Number of UniGram features after TF-IDF transformation: {num_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hr34bTsVYLv9",
   "metadata": {
    "id": "Hr34bTsVYLv9"
   },
   "source": [
    "Implementing Machine Learning Classifiers: Random Forest, Logistic Regression, SVM, Decision Tree, Naive Bayes, MLP, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "na4oomxUHgIT",
   "metadata": {
    "id": "na4oomxUHgIT"
   },
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def parse_classification_report(report, best_params):\n",
    "    flat_report = flatten_dict(report)\n",
    "    flat_report['best_params'] = best_params  # Add 'best_params' information to the flattened report\n",
    "    df = pd.DataFrame.from_dict(flat_report, orient='index').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "xkral1pwOGKO",
   "metadata": {
    "id": "xkral1pwOGKO"
   },
   "outputs": [],
   "source": [
    "classifier_properties = {\n",
    "    'random_forest': {'classifier': RandomForestClassifier(), 'param_grid_value': {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30], 'max_features': ['auto', 'sqrt', 'log2']}},\n",
    "    'logistic_regression': {'classifier': LogisticRegression(), 'param_grid_value': {\"C\": np.logspace(-3, 3, 7), \"penalty\": [\"l2\"],\"multi_class\": [\"ovr\", \"multinomial\"],}},\n",
    "    'svm_classifier': {\n",
    "        'classifier': SVC(),\n",
    "        'param_grid_value': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Different kernel functions\n",
    "            'decision_function_shape': ['ovr', 'ovo'],  # Decision function shape\n",
    "        }\n",
    "    },\n",
    "    'decision_tree': {'classifier': DecisionTreeClassifier(),\n",
    "        'param_grid_value': {\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 10, 20, 30],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "},\n",
    "    'nb_classifier': {'classifier': MultinomialNB(), 'param_grid_value': {'alpha': [0.1, 0.5, 1.0, 2.0]}},\n",
    "    'mlp_classifier': {'classifier': MLPClassifier(), 'param_grid_value': {'hidden_layer_sizes': [(50, 25), (100,)], 'activation': ['relu', 'tanh'], 'alpha': [0.0001, 0.001, 0.01]}},\n",
    "    'SGD_classifier': {'classifier': SGDClassifier(), 'param_grid_value': {'alpha': [0.0001, 0.001, 0.01, 0.1], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'], 'penalty': ['l2', 'l1', 'elasticnet']}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "P3kS6opRfwLu",
   "metadata": {
    "id": "P3kS6opRfwLu"
   },
   "outputs": [],
   "source": [
    "def classify(feature_name, classifier, x_train, y_train, x_test, y_test):\n",
    "  grid_search = GridSearchCV(classifier[\"classifier\"], classifier[\"param_grid_value\"], cv=7, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "  best_params = grid_search.best_params_\n",
    "  best_model = classifier[\"classifier\"].__class__(**best_params)\n",
    "  best_model.fit(x_train, y_train)\n",
    "\n",
    "  # Saving the classifeer...\n",
    "  folder_path = \"C:/Results\"\n",
    "  if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "  pickle_file_path = os.path.join(folder_path, f\"{classifier['classifier'].__class__.__name__}_{feature_name}.pkl\")\n",
    "  with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "  # Evaluate the model on the test dataset\n",
    "  y_pred = best_model.predict(x_test)\n",
    "  report = classification_report(y_test, y_pred, output_dict=True)\n",
    "  #print(classification_report(y_test, y_pred))\n",
    "  print(report)\n",
    "  accuracy = best_model.score(x_test, y_test)\n",
    "  print(f\"Test Set Accuracy: {accuracy:.2f}\")\n",
    "  print(best_params)\n",
    "\n",
    " # Save classification report to CSV file\n",
    "  reports.append({'classifier': classifier['classifier'].__class__.__name__, 'report': report, 'params': best_params})\n",
    "  dfs = []\n",
    "  for report in reports:\n",
    "     classifier_name = report['classifier']\n",
    "     classifier_report = parse_classification_report(report['report'],report['params'])\n",
    "     classifier_report['classifier'] = classifier_name\n",
    "     dfs.append(classifier_report)\n",
    "  combined_report = pd.concat(dfs)\n",
    "  file_path = \"C:/Results/combined_classification_report_\" + feature_name + \".csv\"\n",
    "  combined_report.to_csv(file_path, index=False)\n",
    "  print(f\"Combined classification report saved as 'combined_classification_report_{feature_name}.csv'\")\n",
    "\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "  # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "  # print(\"Confusion Matrix:\")\n",
    "  # print(conf_matrix)\n",
    "  # print(\"\\n\")\n",
    "\n",
    "  # plt.figure(figsize=(5,5))\n",
    "  # sns.heatmap(conf_matrix, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "  # plt.ylabel('Actual label')\n",
    "  # plt.xlabel('Predicted label')\n",
    "  # plt.title('Confusion Matrix', size = 15)\n",
    "  # plt.show()\n",
    "  csv_file_path = os.path.join(folder_path, f\"{classifier['classifier']}_{feature_name}_MissClassified.csv\")\n",
    "  #print(\"Missclassified sentences and their labels\")\n",
    "  misclassified_indice_lables = [(i, true_label, pred_label) for i, (true_label, pred_label) in enumerate(zip(y_test, y_pred)) if true_label != pred_label]\n",
    "\n",
    "  missclassified_sentences = [(X_test.iloc[index], categories[true_label], categories[pred_label])  for (index, true_label, pred_label) in misclassified_indice_lables]\n",
    "  pd.DataFrame(missclassified_sentences, columns=[\"Sentence\", \"True Value\",  \"Predicted Value\"]).to_csv(csv_file_path, index=False)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HjobL7l1YqVD",
   "metadata": {
    "id": "HjobL7l1YqVD"
   },
   "source": [
    "Classification with  CHi2 and Mutual Info Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "GIAWnLcwcfye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIAWnLcwcfye",
    "outputId": "c9a751a5-f2f8-4b8b-a3e3-779ffa55f275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_400\n",
      "chi2_800\n",
      "chi2_1200\n",
      "mi_400\n",
      "mi_800\n",
      "mi_1200\n",
      "uni\n"
     ]
    }
   ],
   "source": [
    "for a in train_set:\n",
    "  print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "YAqI797Do7ME",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAqI797Do7ME",
    "outputId": "450c15f2-d47c-4cc5-89bf-80acd2e2b961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7454545454545455, 'recall': 1.0, 'f1-score': 0.8541666666666666, 'support': 41.0}, '1': {'precision': 0.9642857142857143, 'recall': 0.75, 'f1-score': 0.84375, 'support': 36.0}, '2': {'precision': 0.972972972972973, 'recall': 0.8372093023255814, 'f1-score': 0.9, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8942377442377443, 'recall': 0.8624031007751939, 'f1-score': 0.8659722222222221, 'support': 120.0}, 'weighted avg': {'precision': 0.8926313326313327, 'recall': 0.8666666666666667, 'f1-score': 0.8674652777777777, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.7843137254901961, 'recall': 0.975609756097561, 'f1-score': 0.8695652173913043, 'support': 41.0}, '1': {'precision': 0.9655172413793104, 'recall': 0.7777777777777778, 'f1-score': 0.8615384615384616, 'support': 36.0}, '2': {'precision': 0.9, 'recall': 0.8372093023255814, 'f1-score': 0.8674698795180723, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8832769889565021, 'recall': 0.86353227873364, 'f1-score': 0.8661911861492794, 'support': 120.0}, 'weighted avg': {'precision': 0.8801290286229435, 'recall': 0.8666666666666667, 'f1-score': 0.8664063612308766, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'C': 100.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.7843137254901961, 'recall': 0.975609756097561, 'f1-score': 0.8695652173913043, 'support': 41.0}, '1': {'precision': 0.9333333333333333, 'recall': 0.7777777777777778, 'f1-score': 0.8484848484848485, 'support': 36.0}, '2': {'precision': 0.8717948717948718, 'recall': 0.7906976744186046, 'f1-score': 0.8292682926829268, 'support': 43.0}, 'accuracy': 0.85, 'macro avg': {'precision': 0.8631473102061338, 'recall': 0.8480284027646477, 'f1-score': 0.8491061195196932, 'support': 120.0}, 'weighted avg': {'precision': 0.8603670186023127, 'recall': 0.85, 'f1-score': 0.8488013753655324, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.85\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'rbf'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.6785714285714286, 'recall': 0.926829268292683, 'f1-score': 0.7835051546391752, 'support': 41.0}, '1': {'precision': 0.7741935483870968, 'recall': 0.6666666666666666, 'f1-score': 0.7164179104477612, 'support': 36.0}, '2': {'precision': 0.8787878787878788, 'recall': 0.6744186046511628, 'f1-score': 0.7631578947368421, 'support': 43.0}, 'accuracy': 0.7583333333333333, 'macro avg': {'precision': 0.7771842852488015, 'recall': 0.7559715132035042, 'f1-score': 0.7543603199412595, 'support': 120.0}, 'weighted avg': {'precision': 0.7790022925103571, 'recall': 0.7583333333333333, 'f1-score': 0.7560878799167483, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.76\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.4634146341463415, 'f1-score': 0.6031746031746031, 'support': 41.0}, '1': {'precision': 0.5789473684210527, 'recall': 0.9166666666666666, 'f1-score': 0.7096774193548387, 'support': 36.0}, '2': {'precision': 0.8780487804878049, 'recall': 0.8372093023255814, 'f1-score': 0.8571428571428571, 'support': 43.0}, 'accuracy': 0.7333333333333333, 'macro avg': {'precision': 0.7735441708484071, 'recall': 0.7390968677128632, 'f1-score': 0.723331626557433, 'support': 120.0}, 'weighted avg': {'precision': 0.7833941144435368, 'recall': 0.7333333333333333, 'f1-score': 0.7261307390339647, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.73\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.7647058823529411, 'recall': 0.9512195121951219, 'f1-score': 0.8478260869565217, 'support': 41.0}, '1': {'precision': 0.9032258064516129, 'recall': 0.7777777777777778, 'f1-score': 0.835820895522388, 'support': 36.0}, '2': {'precision': 0.8947368421052632, 'recall': 0.7906976744186046, 'f1-score': 0.8395061728395061, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8542228436366058, 'recall': 0.8398983214638348, 'f1-score': 0.8410510517728053, 'support': 120.0}, 'weighted avg': {'precision': 0.8528562868271247, 'recall': 0.8416666666666667, 'f1-score': 0.8412432269676844, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 25)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8, 'recall': 0.975609756097561, 'f1-score': 0.8791208791208791, 'support': 41.0}, '1': {'precision': 0.9375, 'recall': 0.8333333333333334, 'f1-score': 0.8823529411764706, 'support': 36.0}, '2': {'precision': 0.9210526315789473, 'recall': 0.813953488372093, 'f1-score': 0.8641975308641975, 'support': 43.0}, 'accuracy': 0.875, 'macro avg': {'precision': 0.8861842105263159, 'recall': 0.8742988592676625, 'f1-score': 0.8752237837205157, 'support': 120.0}, 'weighted avg': {'precision': 0.8846271929824563, 'recall': 0.875, 'f1-score': 0.8747429646122457, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7454545454545455, 'recall': 1.0, 'f1-score': 0.8541666666666666, 'support': 41.0}, '1': {'precision': 0.9615384615384616, 'recall': 0.6944444444444444, 'f1-score': 0.8064516129032258, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.85, 'macro avg': {'precision': 0.8766899766899767, 'recall': 0.8438845822566753, 'f1-score': 0.8462223533525658, 'support': 120.0}, 'weighted avg': {'precision': 0.8739277389277389, 'recall': 0.85, 'f1-score': 0.848409907990209, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.85\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8666666666666667, 'recall': 0.9512195121951219, 'f1-score': 0.9069767441860465, 'support': 41.0}, '1': {'precision': 0.9411764705882353, 'recall': 0.8888888888888888, 'f1-score': 0.9142857142857143, 'support': 36.0}, '2': {'precision': 0.926829268292683, 'recall': 0.8837209302325582, 'f1-score': 0.9047619047619048, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9115574685158617, 'recall': 0.9079431104388563, 'f1-score': 0.9086747877445552, 'support': 120.0}, 'weighted avg': {'precision': 0.9105778734257931, 'recall': 0.9083333333333333, 'f1-score': 0.908375784422296, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8478260869565217, 'recall': 0.9512195121951219, 'f1-score': 0.896551724137931, 'support': 41.0}, '1': {'precision': 0.9428571428571428, 'recall': 0.9166666666666666, 'f1-score': 0.9295774647887324, 'support': 36.0}, '2': {'precision': 0.9487179487179487, 'recall': 0.8604651162790697, 'f1-score': 0.9024390243902439, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9131337261772045, 'recall': 0.9094504317136195, 'f1-score': 0.9095227377723024, 'support': 120.0}, 'weighted avg': {'precision': 0.912488320857886, 'recall': 0.9083333333333333, 'f1-score': 0.908569062256917, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'rbf'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.6727272727272727, 'recall': 0.9024390243902439, 'f1-score': 0.7708333333333334, 'support': 41.0}, '1': {'precision': 0.6129032258064516, 'recall': 0.5277777777777778, 'f1-score': 0.5671641791044776, 'support': 36.0}, '2': {'precision': 0.7647058823529411, 'recall': 0.6046511627906976, 'f1-score': 0.6753246753246753, 'support': 43.0}, 'accuracy': 0.6833333333333333, 'macro avg': {'precision': 0.6834454602955552, 'recall': 0.6782893216529065, 'f1-score': 0.6711073959208287, 'support': 120.0}, 'weighted avg': {'precision': 0.6877390604335576, 'recall': 0.6833333333333333, 'f1-score': 0.6755086512782408, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.68\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.896551724137931, 'recall': 0.6341463414634146, 'f1-score': 0.7428571428571429, 'support': 41.0}, '1': {'precision': 0.6808510638297872, 'recall': 0.8888888888888888, 'f1-score': 0.7710843373493976, 'support': 36.0}, '2': {'precision': 0.8863636363636364, 'recall': 0.9069767441860465, 'f1-score': 0.896551724137931, 'support': 43.0}, 'accuracy': 0.8083333333333333, 'macro avg': {'precision': 0.8212554747771182, 'recall': 0.8100039915127834, 'f1-score': 0.8034977347814906, 'support': 120.0}, 'weighted avg': {'precision': 0.8281907945930324, 'recall': 0.8083333333333333, 'f1-score': 0.806399192830435, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.81\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8863636363636364, 'recall': 0.9512195121951219, 'f1-score': 0.9176470588235294, 'support': 41.0}, '1': {'precision': 0.9090909090909091, 'recall': 0.8333333333333334, 'f1-score': 0.8695652173913043, 'support': 36.0}, '2': {'precision': 0.9069767441860465, 'recall': 0.9069767441860465, 'f1-score': 0.9069767441860465, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.9008104298801972, 'recall': 0.8971765299048339, 'f1-score': 0.8980630068002934, 'support': 120.0}, 'weighted avg': {'precision': 0.9005681818181818, 'recall': 0.9, 'f1-score': 0.8993989769820971, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.926829268292683, 'f1-score': 0.8941176470588236, 'support': 41.0}, '1': {'precision': 0.9428571428571428, 'recall': 0.9166666666666666, 'f1-score': 0.9295774647887324, 'support': 36.0}, '2': {'precision': 0.926829268292683, 'recall': 0.8837209302325582, 'f1-score': 0.9047619047619048, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9111075915953964, 'recall': 0.9090722883973026, 'f1-score': 0.9094856722031536, 'support': 120.0}, 'weighted avg': {'precision': 0.9100467215711119, 'recall': 0.9083333333333333, 'f1-score': 0.9085697847214003, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7321428571428571, 'recall': 1.0, 'f1-score': 0.845360824742268, 'support': 41.0}, '1': {'precision': 0.9642857142857143, 'recall': 0.75, 'f1-score': 0.84375, 'support': 36.0}, '2': {'precision': 0.9166666666666666, 'recall': 0.7674418604651163, 'f1-score': 0.8354430379746836, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.871031746031746, 'recall': 0.8391472868217055, 'f1-score': 0.8415179542389839, 'support': 120.0}, 'weighted avg': {'precision': 0.867906746031746, 'recall': 0.8416666666666667, 'f1-score': 0.8413237037278698, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8444444444444444, 'recall': 0.926829268292683, 'f1-score': 0.8837209302325582, 'support': 41.0}, '1': {'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1-score': 0.9166666666666666, 'support': 36.0}, '2': {'precision': 0.9487179487179487, 'recall': 0.8604651162790697, 'f1-score': 0.9024390243902439, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.9032763532763534, 'recall': 0.9013203504128064, 'f1-score': 0.9009422070964895, 'support': 120.0}, 'weighted avg': {'precision': 0.9034757834757835, 'recall': 0.9, 'f1-score': 0.9003119682359615, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.926829268292683, 'f1-score': 0.8941176470588236, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.9512195121951219, 'recall': 0.9069767441860465, 'f1-score': 0.9285714285714286, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9097138633723999, 'recall': 0.9075649671225393, 'f1-score': 0.9080325087781592, 'support': 120.0}, 'weighted avg': {'precision': 0.9102151303980572, 'recall': 0.9083333333333333, 'f1-score': 0.9086508265277943, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'linear'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7450980392156863, 'recall': 0.926829268292683, 'f1-score': 0.8260869565217391, 'support': 41.0}, '1': {'precision': 0.7272727272727273, 'recall': 0.6666666666666666, 'f1-score': 0.6956521739130435, 'support': 36.0}, '2': {'precision': 0.8888888888888888, 'recall': 0.7441860465116279, 'f1-score': 0.810126582278481, 'support': 43.0}, 'accuracy': 0.7833333333333333, 'macro avg': {'precision': 0.787086551792434, 'recall': 0.7792273271569924, 'f1-score': 0.7772885709044212, 'support': 120.0}, 'weighted avg': {'precision': 0.7912755000990295, 'recall': 0.7833333333333333, 'f1-score': 0.7812373876352962, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9310344827586207, 'recall': 0.6585365853658537, 'f1-score': 0.7714285714285715, 'support': 41.0}, '1': {'precision': 0.7021276595744681, 'recall': 0.9166666666666666, 'f1-score': 0.7951807228915663, 'support': 36.0}, '2': {'precision': 0.9090909090909091, 'recall': 0.9302325581395349, 'f1-score': 0.9195402298850575, 'support': 43.0}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.8474176838079993, 'recall': 0.8351452700573517, 'f1-score': 0.8287165080683984, 'support': 120.0}, 'weighted avg': {'precision': 0.8544993219057783, 'recall': 0.8333333333333334, 'f1-score': 0.8316275611477107, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.83\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.926829268292683, 'f1-score': 0.8941176470588236, 'support': 41.0}, '1': {'precision': 0.8888888888888888, 'recall': 0.8888888888888888, 'f1-score': 0.8888888888888888, 'support': 36.0}, '2': {'precision': 0.925, 'recall': 0.8604651162790697, 'f1-score': 0.891566265060241, 'support': 43.0}, 'accuracy': 0.8916666666666667, 'macro avg': {'precision': 0.8925084175084175, 'recall': 0.8920610911535473, 'f1-score': 0.8915242670026511, 'support': 120.0}, 'weighted avg': {'precision': 0.8932007575757576, 'recall': 0.8916666666666667, 'f1-score': 0.8916347743916844, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.89\n",
      "{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (50, 25)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8809523809523809, 'recall': 0.9024390243902439, 'f1-score': 0.891566265060241, 'support': 41.0}, '1': {'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1-score': 0.9166666666666666, 'support': 36.0}, '2': {'precision': 0.9285714285714286, 'recall': 0.9069767441860465, 'f1-score': 0.9176470588235294, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9087301587301587, 'recall': 0.9086941450809857, 'f1-score': 0.9086266635168122, 'support': 120.0}, 'weighted avg': {'precision': 0.9087301587301587, 'recall': 0.9083333333333333, 'f1-score': 0.9084420033073469, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7547169811320755, 'recall': 0.975609756097561, 'f1-score': 0.851063829787234, 'support': 41.0}, '1': {'precision': 0.9333333333333333, 'recall': 0.7777777777777778, 'f1-score': 0.8484848484848485, 'support': 36.0}, '2': {'precision': 0.9459459459459459, 'recall': 0.813953488372093, 'f1-score': 0.875, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8779987534704516, 'recall': 0.8557803407491439, 'f1-score': 0.8581828927573608, 'support': 120.0}, 'weighted avg': {'precision': 0.8768255991840898, 'recall': 0.8583333333333333, 'f1-score': 0.8588672630560928, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 300}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8085106382978723, 'recall': 0.926829268292683, 'f1-score': 0.8636363636363636, 'support': 41.0}, '1': {'precision': 0.9090909090909091, 'recall': 0.8333333333333334, 'f1-score': 0.8695652173913043, 'support': 36.0}, '2': {'precision': 0.925, 'recall': 0.8604651162790697, 'f1-score': 0.891566265060241, 'support': 43.0}, 'accuracy': 0.875, 'macro avg': {'precision': 0.8808671824629272, 'recall': 0.8735425726350288, 'f1-score': 0.8749226153626363, 'support': 120.0}, 'weighted avg': {'precision': 0.8804267408123791, 'recall': 0.875, 'f1-score': 0.8754232344397351, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.75, 'recall': 0.8780487804878049, 'f1-score': 0.8089887640449438, 'support': 41.0}, '1': {'precision': 0.9032258064516129, 'recall': 0.7777777777777778, 'f1-score': 0.835820895522388, 'support': 36.0}, '2': {'precision': 0.8780487804878049, 'recall': 0.8372093023255814, 'f1-score': 0.8571428571428571, 'support': 43.0}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.8437581956464726, 'recall': 0.831011953530388, 'f1-score': 0.8339841722367297, 'support': 120.0}, 'weighted avg': {'precision': 0.8418518882769473, 'recall': 0.8333333333333334, 'f1-score': 0.8342936201815959, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.83\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.6862745098039216, 'recall': 0.8536585365853658, 'f1-score': 0.7608695652173914, 'support': 41.0}, '1': {'precision': 0.6875, 'recall': 0.6111111111111112, 'f1-score': 0.6470588235294118, 'support': 36.0}, '2': {'precision': 0.8378378378378378, 'recall': 0.7209302325581395, 'f1-score': 0.775, 'support': 43.0}, 'accuracy': 0.7333333333333333, 'macro avg': {'precision': 0.7372041158805865, 'recall': 0.7285666267515388, 'f1-score': 0.7276427962489344, 'support': 120.0}, 'weighted avg': {'precision': 0.7409523494082317, 'recall': 0.7333333333333333, 'f1-score': 0.731789748508099, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.73\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.75, 'recall': 0.5853658536585366, 'f1-score': 0.6575342465753424, 'support': 41.0}, '1': {'precision': 0.6595744680851063, 'recall': 0.8611111111111112, 'f1-score': 0.7469879518072289, 'support': 36.0}, '2': {'precision': 0.8536585365853658, 'recall': 0.813953488372093, 'f1-score': 0.8333333333333334, 'support': 43.0}, 'accuracy': 0.75, 'macro avg': {'precision': 0.7544110015568241, 'recall': 0.7534768177139136, 'f1-score': 0.7459518439053016, 'support': 120.0}, 'weighted avg': {'precision': 0.7600166493686212, 'recall': 0.75, 'f1-score': 0.7473650308998551, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.75\n",
      "{'alpha': 2.0}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.782608695652174, 'recall': 0.8780487804878049, 'f1-score': 0.8275862068965517, 'support': 41.0}, '1': {'precision': 0.8571428571428571, 'recall': 0.8333333333333334, 'f1-score': 0.8450704225352113, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.85, 'macro avg': {'precision': 0.8542761586239846, 'recall': 0.8495304720489066, 'f1-score': 0.850235136639856, 'support': 120.0}, 'weighted avg': {'precision': 0.855303392259914, 'recall': 0.85, 'f1-score': 0.8509138937916819, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.85\n",
      "{'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8222222222222222, 'recall': 0.9024390243902439, 'f1-score': 0.8604651162790697, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.8837209302325582, 'recall': 0.8837209302325582, 'f1-score': 0.8837209302325582, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8707310508182601, 'recall': 0.8639051700594527, 'f1-score': 0.8657090743274054, 'support': 120.0}, 'weighted avg': {'precision': 0.8694675925925925, 'recall': 0.8666666666666667, 'f1-score': 0.8665412676698587, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7407407407407407, 'recall': 0.975609756097561, 'f1-score': 0.8421052631578947, 'support': 41.0}, '1': {'precision': 0.875, 'recall': 0.7777777777777778, 'f1-score': 0.8235294117647058, 'support': 36.0}, '2': {'precision': 0.9411764705882353, 'recall': 0.7441860465116279, 'f1-score': 0.8311688311688312, 'support': 43.0}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.8523057371096586, 'recall': 0.8325245267956555, 'f1-score': 0.8322678353638105, 'support': 120.0}, 'weighted avg': {'precision': 0.8528413217138707, 'recall': 0.8333333333333334, 'f1-score': 0.8326136196105236, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.83\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 300}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.7755102040816326, 'recall': 0.926829268292683, 'f1-score': 0.8444444444444444, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8682790423861851, 'recall': 0.8565313753912734, 'f1-score': 0.8584781338009458, 'support': 120.0}, 'weighted avg': {'precision': 0.8676102171637886, 'recall': 0.8583333333333333, 'f1-score': 0.8590350178011583, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.7916666666666666, 'recall': 0.926829268292683, 'f1-score': 0.8539325842696629, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.925, 'recall': 0.8604651162790697, 'f1-score': 0.891566265060241, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8743055555555556, 'recall': 0.8642833133757696, 'f1-score': 0.8661466752668306, 'support': 120.0}, 'weighted avg': {'precision': 0.8738194444444444, 'recall': 0.8666666666666667, 'f1-score': 0.8671205642132309, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7692307692307693, 'recall': 0.975609756097561, 'f1-score': 0.8602150537634409, 'support': 41.0}, '1': {'precision': 0.8181818181818182, 'recall': 0.75, 'f1-score': 0.782608695652174, 'support': 36.0}, '2': {'precision': 0.8571428571428571, 'recall': 0.6976744186046512, 'f1-score': 0.7692307692307693, 'support': 43.0}, 'accuracy': 0.8083333333333333, 'macro avg': {'precision': 0.8148518148518149, 'recall': 0.807761391567404, 'f1-score': 0.804018172882128, 'support': 120.0}, 'weighted avg': {'precision': 0.8154179154179154, 'recall': 0.8083333333333333, 'f1-score': 0.8043304443725201, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.81\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.7575757575757576, 'recall': 0.6097560975609756, 'f1-score': 0.6756756756756757, 'support': 41.0}, '1': {'precision': 0.6956521739130435, 'recall': 0.8888888888888888, 'f1-score': 0.7804878048780488, 'support': 36.0}, '2': {'precision': 0.8780487804878049, 'recall': 0.8372093023255814, 'f1-score': 0.8571428571428571, 'support': 43.0}, 'accuracy': 0.775, 'macro avg': {'precision': 0.7770922373255353, 'recall': 0.778618096258482, 'f1-score': 0.7711021125655272, 'support': 120.0}, 'weighted avg': {'precision': 0.7821681823537603, 'recall': 0.775, 'f1-score': 0.7721450544621277, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'alpha': 1.0}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.7959183673469388, 'recall': 0.9512195121951219, 'f1-score': 0.8666666666666667, 'support': 41.0}, '1': {'precision': 0.8529411764705882, 'recall': 0.8055555555555556, 'f1-score': 0.8285714285714286, 'support': 36.0}, '2': {'precision': 0.9459459459459459, 'recall': 0.813953488372093, 'f1-score': 0.875, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8649351632544909, 'recall': 0.8569095187075901, 'f1-score': 0.8567460317460318, 'support': 120.0}, 'weighted avg': {'precision': 0.8667850924153445, 'recall': 0.8583333333333333, 'f1-score': 0.8582242063492063, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.7916666666666666, 'recall': 0.926829268292683, 'f1-score': 0.8539325842696629, 'support': 41.0}, '1': {'precision': 0.9032258064516129, 'recall': 0.7777777777777778, 'f1-score': 0.835820895522388, 'support': 36.0}, '2': {'precision': 0.926829268292683, 'recall': 0.8837209302325582, 'f1-score': 0.9047619047619048, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8739072471369874, 'recall': 0.8627759921010063, 'f1-score': 0.8648384615179853, 'support': 120.0}, 'weighted avg': {'precision': 0.8735676741848064, 'recall': 0.8666666666666667, 'f1-score': 0.8667129174885336, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7358490566037735, 'recall': 0.9512195121951219, 'f1-score': 0.8297872340425532, 'support': 41.0}, '1': {'precision': 0.8529411764705882, 'recall': 0.8055555555555556, 'f1-score': 0.8285714285714286, 'support': 36.0}, '2': {'precision': 0.9393939393939394, 'recall': 0.7209302325581395, 'f1-score': 0.8157894736842105, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8427280574894338, 'recall': 0.8259017667696057, 'f1-score': 0.8247160454327308, 'support': 120.0}, 'weighted avg': {'precision': 0.8439136088969607, 'recall': 0.825, 'f1-score': 0.8244066282728096, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 300}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8260869565217391, 'recall': 0.926829268292683, 'f1-score': 0.8735632183908046, 'support': 41.0}, '1': {'precision': 0.8857142857142857, 'recall': 0.8611111111111112, 'f1-score': 0.8732394366197183, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.875, 'macro avg': {'precision': 0.8782927217709826, 'recall': 0.8750498939097918, 'f1-score': 0.8749504784994425, 'support': 120.0}, 'weighted avg': {'precision': 0.8787298932951106, 'recall': 0.875, 'f1-score': 0.8750734102775705, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 1.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.6818181818181818, 'recall': 0.7317073170731707, 'f1-score': 0.7058823529411765, 'support': 41.0}, '1': {'precision': 0.7352941176470589, 'recall': 0.6944444444444444, 'f1-score': 0.7142857142857143, 'support': 36.0}, '2': {'precision': 0.8809523809523809, 'recall': 0.8604651162790697, 'f1-score': 0.8705882352941177, 'support': 43.0}, 'accuracy': 0.7666666666666667, 'macro avg': {'precision': 0.7660215601392072, 'recall': 0.7622056259322282, 'f1-score': 0.7635854341736694, 'support': 120.0}, 'weighted avg': {'precision': 0.7692173839232662, 'recall': 0.7666666666666667, 'f1-score': 0.7674229691876752, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.77\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'rbf'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7083333333333334, 'recall': 0.8292682926829268, 'f1-score': 0.7640449438202247, 'support': 41.0}, '1': {'precision': 0.7027027027027027, 'recall': 0.7222222222222222, 'f1-score': 0.7123287671232876, 'support': 36.0}, '2': {'precision': 0.7428571428571429, 'recall': 0.6046511627906976, 'f1-score': 0.6666666666666666, 'support': 43.0}, 'accuracy': 0.7166666666666667, 'macro avg': {'precision': 0.717964392964393, 'recall': 0.7187138925652823, 'f1-score': 0.7143467925367263, 'support': 120.0}, 'weighted avg': {'precision': 0.7190151758901758, 'recall': 0.7166666666666667, 'f1-score': 0.713636208164452, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.72\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9655172413793104, 'recall': 0.6829268292682927, 'f1-score': 0.8, 'support': 41.0}, '1': {'precision': 0.6875, 'recall': 0.9166666666666666, 'f1-score': 0.7857142857142857, 'support': 36.0}, '2': {'precision': 0.8837209302325582, 'recall': 0.8837209302325582, 'f1-score': 0.8837209302325582, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8455793905372895, 'recall': 0.8277714753891724, 'f1-score': 0.8231450719822814, 'support': 120.0}, 'weighted avg': {'precision': 0.852801724137931, 'recall': 0.825, 'f1-score': 0.8257142857142857, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'alpha': 0.5}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8055555555555556, 'recall': 0.7073170731707317, 'f1-score': 0.7532467532467533, 'support': 41.0}, '1': {'precision': 0.6956521739130435, 'recall': 0.8888888888888888, 'f1-score': 0.7804878048780488, 'support': 36.0}, '2': {'precision': 0.9473684210526315, 'recall': 0.8372093023255814, 'f1-score': 0.8888888888888888, 'support': 43.0}, 'accuracy': 0.8083333333333333, 'macro avg': {'precision': 0.8161920501737435, 'recall': 0.811138421461734, 'f1-score': 0.8075411490045635, 'support': 120.0}, 'weighted avg': {'precision': 0.8234008178659208, 'recall': 0.8083333333333333, 'f1-score': 0.8100241673412405, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.81\n",
      "{'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8, 'recall': 0.8780487804878049, 'f1-score': 0.8372093023255814, 'support': 41.0}, '1': {'precision': 0.9310344827586207, 'recall': 0.75, 'f1-score': 0.8307692307692308, 'support': 36.0}, '2': {'precision': 0.8478260869565217, 'recall': 0.9069767441860465, 'f1-score': 0.8764044943820225, 'support': 43.0}, 'accuracy': 0.85, 'macro avg': {'precision': 0.8596201899050474, 'recall': 0.845008508224617, 'f1-score': 0.8481276758256117, 'support': 120.0}, 'weighted avg': {'precision': 0.8564480259870065, 'recall': 0.85, 'f1-score': 0.849322224678901, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.85\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7222222222222222, 'recall': 0.9512195121951219, 'f1-score': 0.8210526315789474, 'support': 41.0}, '1': {'precision': 0.9333333333333333, 'recall': 0.7777777777777778, 'f1-score': 0.8484848484848485, 'support': 36.0}, '2': {'precision': 0.9444444444444444, 'recall': 0.7906976744186046, 'f1-score': 0.8607594936708861, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8666666666666666, 'recall': 0.8398983214638348, 'f1-score': 0.8434323245782274, 'support': 120.0}, 'weighted avg': {'precision': 0.8651851851851852, 'recall': 0.8416666666666667, 'f1-score': 0.8435105889003292, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8444444444444444, 'recall': 0.926829268292683, 'f1-score': 0.8837209302325582, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.95, 'recall': 0.8837209302325582, 'f1-score': 0.9156626506024096, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.902910052910053, 'recall': 0.8998130291380434, 'f1-score': 0.9002640105130643, 'support': 120.0}, 'weighted avg': {'precision': 0.9032208994708995, 'recall': 0.9, 'f1-score': 0.9004729695065884, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'C': 100.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8604651162790697, 'recall': 0.9024390243902439, 'f1-score': 0.8809523809523809, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.9285714285714286, 'recall': 0.9069767441860465, 'f1-score': 0.9176470588235294, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.901107419712071, 'recall': 0.8994348858217264, 'f1-score': 0.9000026301600452, 'support': 120.0}, 'weighted avg': {'precision': 0.9010160575858249, 'recall': 0.9, 'f1-score': 0.9002381281150957, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7551020408163265, 'recall': 0.9024390243902439, 'f1-score': 0.8222222222222222, 'support': 41.0}, '1': {'precision': 0.7352941176470589, 'recall': 0.6944444444444444, 'f1-score': 0.7142857142857143, 'support': 36.0}, '2': {'precision': 0.8648648648648649, 'recall': 0.7441860465116279, 'f1-score': 0.8, 'support': 43.0}, 'accuracy': 0.7833333333333333, 'macro avg': {'precision': 0.7850870077760833, 'recall': 0.7803565051154387, 'f1-score': 0.7788359788359788, 'support': 120.0}, 'weighted avg': {'precision': 0.7884913424829392, 'recall': 0.7833333333333333, 'f1-score': 0.7818783068783068, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9310344827586207, 'recall': 0.6585365853658537, 'f1-score': 0.7714285714285715, 'support': 41.0}, '1': {'precision': 0.7441860465116279, 'recall': 0.8888888888888888, 'f1-score': 0.810126582278481, 'support': 36.0}, '2': {'precision': 0.8333333333333334, 'recall': 0.9302325581395349, 'f1-score': 0.8791208791208791, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8361846208678606, 'recall': 0.8258860107980924, 'f1-score': 0.8202253442759773, 'support': 120.0}, 'weighted avg': {'precision': 0.8399703733404617, 'recall': 0.825, 'f1-score': 0.8216277182732878, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'alpha': 0.5}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8409090909090909, 'recall': 0.9024390243902439, 'f1-score': 0.8705882352941177, 'support': 41.0}, '1': {'precision': 0.9117647058823529, 'recall': 0.8611111111111112, 'f1-score': 0.8857142857142857, 'support': 36.0}, '2': {'precision': 0.9047619047619048, 'recall': 0.8837209302325582, 'f1-score': 0.8941176470588236, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8858119005177829, 'recall': 0.8824236885779712, 'f1-score': 0.8834733893557423, 'support': 120.0}, 'weighted avg': {'precision': 0.8850463670316612, 'recall': 0.8833333333333333, 'f1-score': 0.8835574229691877, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8260869565217391, 'recall': 0.926829268292683, 'f1-score': 0.8735632183908046, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8878165312947921, 'recall': 0.8843091531690511, 'f1-score': 0.8843401498609449, 'support': 120.0}, 'weighted avg': {'precision': 0.8873013218665393, 'recall': 0.8833333333333333, 'f1-score': 0.8835241145029225, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'alpha': 0.01, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, train_set_key in enumerate(train_set):\n",
    "  reports = []\n",
    "  for classifier in classifier_properties:\n",
    "    print(f\"Classification for model: {classifier}\")\n",
    "    classify(feature_name=train_set_key,\n",
    "             classifier=classifier_properties[classifier],\n",
    "             x_train=train_set.get(train_set_key)[\"train\"],\n",
    "             y_train=y_train,\n",
    "             x_test=train_set.get(train_set_key)[\"test\"],\n",
    "             y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y8lV-Jt99EH7",
   "metadata": {
    "id": "y8lV-Jt99EH7"
   },
   "source": [
    "Loading all classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "Oi2oYj0bIwOm",
   "metadata": {
    "id": "Oi2oYj0bIwOm"
   },
   "outputs": [],
   "source": [
    "report_chi2_400 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_400.csv\")\n",
    "report_chi2_800 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_800.csv\")\n",
    "report_chi2_1200 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_1200.csv\")\n",
    "\n",
    "report_mi_400 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_400.csv\")\n",
    "report_mi_800 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_800.csv\")\n",
    "report_mi_1200 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_1200.csv\")\n",
    "\n",
    "report_uni = pd.read_csv(\"C:\\Results\\combined_classification_report_uni.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "RPBhF16itQll",
   "metadata": {
    "id": "RPBhF16itQll"
   },
   "outputs": [],
   "source": [
    "def prepare_report(df, feature_selection_tag):\n",
    "    df = df[['classifier', 'accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score', 'best_params']]\n",
    "    # Add a new column with a fixed value indicating the feature selection method\n",
    "    df['Feature Selection'] = [feature_selection_tag] * len(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "v0TVyC4FpTih",
   "metadata": {
    "id": "v0TVyC4FpTih"
   },
   "outputs": [],
   "source": [
    "report_chi2_400 = prepare_report(report_chi2_400, 'chi2_400')\n",
    "report_chi2_800 = prepare_report(report_chi2_800, 'chi2_800')\n",
    "report_chi2_1200 = prepare_report(report_chi2_1200, 'chi2_1200')\n",
    "\n",
    "report_mi_400 = prepare_report(report_mi_400, 'mi_400')\n",
    "report_mi_800 = prepare_report(report_mi_800, 'mi_800')\n",
    "report_mi_1200 = prepare_report(report_mi_1200, 'mi_1200')\n",
    "\n",
    "report_uni = prepare_report(report_uni, 'All features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "Ndn6unaFdbC7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Ndn6unaFdbC7",
    "outputId": "79d9da08-4a51-4ed6-c005-f2461f0042d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'multinomial', 'pe...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.849</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.754</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.723</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.841</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.875</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.846</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.909</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'ovr', 'penalty': ...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.910</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.671</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.803</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.898</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.842</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'ovr', 'penalty': ...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.908</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.777</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.829</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.892</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0   RandomForestClassifier     0.867                0.894             0.862   \n",
       "1       LogisticRegression     0.867                0.883             0.864   \n",
       "2                      SVC     0.850                0.863             0.848   \n",
       "3   DecisionTreeClassifier     0.758                0.777             0.756   \n",
       "4            MultinomialNB     0.733                0.774             0.739   \n",
       "5            MLPClassifier     0.842                0.854             0.840   \n",
       "6            SGDClassifier     0.875                0.886             0.874   \n",
       "7   RandomForestClassifier     0.850                0.877             0.844   \n",
       "8       LogisticRegression     0.908                0.912             0.908   \n",
       "9                      SVC     0.908                0.913             0.909   \n",
       "10  DecisionTreeClassifier     0.683                0.683             0.678   \n",
       "11           MultinomialNB     0.808                0.821             0.810   \n",
       "12           MLPClassifier     0.900                0.901             0.897   \n",
       "13           SGDClassifier     0.908                0.911             0.909   \n",
       "14  RandomForestClassifier     0.842                0.871             0.839   \n",
       "15      LogisticRegression     0.900                0.903             0.901   \n",
       "16                     SVC     0.908                0.910             0.908   \n",
       "17  DecisionTreeClassifier     0.783                0.787             0.779   \n",
       "18           MultinomialNB     0.833                0.847             0.835   \n",
       "19           MLPClassifier     0.892                0.893             0.892   \n",
       "20           SGDClassifier     0.908                0.909             0.909   \n",
       "\n",
       "    macro avg_f1-score                                        best_params  \\\n",
       "0                0.866  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "1                0.866  {'C': 100.0, 'multi_class': 'multinomial', 'pe...   \n",
       "2                0.849  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "3                0.754  {'criterion': 'entropy', 'max_depth': None, 'm...   \n",
       "4                0.723                                     {'alpha': 0.1}   \n",
       "5                0.841  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "6                0.875  {'alpha': 0.001, 'loss': 'modified_huber', 'pe...   \n",
       "7                0.846  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "8                0.909  {'C': 100.0, 'multi_class': 'ovr', 'penalty': ...   \n",
       "9                0.910  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "10               0.671  {'criterion': 'entropy', 'max_depth': None, 'm...   \n",
       "11               0.803                                     {'alpha': 0.1}   \n",
       "12               0.898  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "13               0.909  {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...   \n",
       "14               0.842  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "15               0.901  {'C': 100.0, 'multi_class': 'ovr', 'penalty': ...   \n",
       "16               0.908  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "17               0.777  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "18               0.829                                     {'alpha': 0.1}   \n",
       "19               0.892  {'activation': 'tanh', 'alpha': 0.001, 'hidden...   \n",
       "20               0.909  {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...   \n",
       "\n",
       "   Feature Selection  \n",
       "0           chi2_400  \n",
       "1           chi2_400  \n",
       "2           chi2_400  \n",
       "3           chi2_400  \n",
       "4           chi2_400  \n",
       "5           chi2_400  \n",
       "6           chi2_400  \n",
       "7           chi2_800  \n",
       "8           chi2_800  \n",
       "9           chi2_800  \n",
       "10          chi2_800  \n",
       "11          chi2_800  \n",
       "12          chi2_800  \n",
       "13          chi2_800  \n",
       "14         chi2_1200  \n",
       "15         chi2_1200  \n",
       "16         chi2_1200  \n",
       "17         chi2_1200  \n",
       "18         chi2_1200  \n",
       "19         chi2_1200  \n",
       "20         chi2_1200  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_chi2_400 = pd.DataFrame(report_chi2_400)\n",
    "df_report_chi2_800 = pd.DataFrame(report_chi2_800)\n",
    "df_report_chi2_1200 = pd.DataFrame(report_chi2_1200)\n",
    "\n",
    "merge_df_chi2 = pd.concat([df_report_chi2_400,df_report_chi2_800,df_report_chi2_1200], axis=0)\n",
    "merge_df_chi2.reset_index(drop=True, inplace=True)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "merge_df_chi2[columns_to_round] = merge_df_chi2[columns_to_round].apply(lambda x: round(x, 3))\n",
    "merge_df_chi2.to_csv(r'C:\\results\\report_chi2.csv', index=False)\n",
    "merge_df_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "tl01bFLTqr8v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "tl01bFLTqr8v",
    "outputId": "3744f4ec-fd16-4efd-b57d-c5c8624190f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.858</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.875</td>\n",
       "      <td>{'C': 10.0, 'multi_class': 'ovr', 'penalty': '...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.834</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.728</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.746</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.832</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.858</td>\n",
       "      <td>{'C': 10.0, 'multi_class': 'ovr', 'penalty': '...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.804</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.771</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.857</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.865</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.825</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>{'C': 1.0, 'multi_class': 'multinomial', 'pena...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.764</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.714</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.823</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.808</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.848</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0   RandomForestClassifier     0.858                0.878             0.856   \n",
       "1       LogisticRegression     0.875                0.881             0.874   \n",
       "2                      SVC     0.833                0.844             0.831   \n",
       "3   DecisionTreeClassifier     0.733                0.737             0.729   \n",
       "4            MultinomialNB     0.750                0.754             0.753   \n",
       "5            MLPClassifier     0.850                0.854             0.850   \n",
       "6            SGDClassifier     0.867                0.871             0.864   \n",
       "7   RandomForestClassifier     0.833                0.852             0.833   \n",
       "8       LogisticRegression     0.858                0.868             0.857   \n",
       "9                      SVC     0.867                0.874             0.864   \n",
       "10  DecisionTreeClassifier     0.808                0.815             0.808   \n",
       "11           MultinomialNB     0.775                0.777             0.779   \n",
       "12           MLPClassifier     0.858                0.865             0.857   \n",
       "13           SGDClassifier     0.867                0.874             0.863   \n",
       "14  RandomForestClassifier     0.825                0.843             0.826   \n",
       "15      LogisticRegression     0.875                0.878             0.875   \n",
       "16                     SVC     0.767                0.766             0.762   \n",
       "17  DecisionTreeClassifier     0.717                0.718             0.719   \n",
       "18           MultinomialNB     0.825                0.846             0.828   \n",
       "19           MLPClassifier     0.808                0.816             0.811   \n",
       "20           SGDClassifier     0.850                0.860             0.845   \n",
       "\n",
       "    macro avg_f1-score                                        best_params  \\\n",
       "0                0.858  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "1                0.875  {'C': 10.0, 'multi_class': 'ovr', 'penalty': '...   \n",
       "2                0.834  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "3                0.728  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "4                0.746                                     {'alpha': 2.0}   \n",
       "5                0.850  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...   \n",
       "6                0.866  {'alpha': 0.001, 'loss': 'modified_huber', 'pe...   \n",
       "7                0.832  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "8                0.858  {'C': 10.0, 'multi_class': 'ovr', 'penalty': '...   \n",
       "9                0.866  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "10               0.804  {'criterion': 'entropy', 'max_depth': None, 'm...   \n",
       "11               0.771                                     {'alpha': 1.0}   \n",
       "12               0.857  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "13               0.865  {'alpha': 0.001, 'loss': 'modified_huber', 'pe...   \n",
       "14               0.825  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "15               0.875  {'C': 1.0, 'multi_class': 'multinomial', 'pena...   \n",
       "16               0.764  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "17               0.714  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "18               0.823                                     {'alpha': 0.5}   \n",
       "19               0.808  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...   \n",
       "20               0.848  {'alpha': 0.001, 'loss': 'modified_huber', 'pe...   \n",
       "\n",
       "   Feature Selection  \n",
       "0             mi_400  \n",
       "1             mi_400  \n",
       "2             mi_400  \n",
       "3             mi_400  \n",
       "4             mi_400  \n",
       "5             mi_400  \n",
       "6             mi_400  \n",
       "7             mi_800  \n",
       "8             mi_800  \n",
       "9             mi_800  \n",
       "10            mi_800  \n",
       "11            mi_800  \n",
       "12            mi_800  \n",
       "13            mi_800  \n",
       "14           mi_1200  \n",
       "15           mi_1200  \n",
       "16           mi_1200  \n",
       "17           mi_1200  \n",
       "18           mi_1200  \n",
       "19           mi_1200  \n",
       "20           mi_1200  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mi_400 = pd.DataFrame(report_mi_400)\n",
    "df_report_mi_800 = pd.DataFrame(report_mi_800)\n",
    "df_report_mi_1200 = pd.DataFrame(report_mi_1200)\n",
    "\n",
    "merge_df_mi = pd.concat([df_report_mi_400,df_report_mi_800,df_report_mi_1200], axis=0)\n",
    "merge_df_mi.reset_index(drop=True, inplace=True)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "merge_df_mi[columns_to_round] = merge_df_mi[columns_to_round].apply(lambda x: round(x, 3))\n",
    "merge_df_mi.to_csv(r'C:\\results\\report_mi.csv', index=False)\n",
    "merge_df_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "VtkeF2NbQJol",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "VtkeF2NbQJol",
    "outputId": "2f856c68-6e93-44da-e4cb-b537ccb9f31f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.843</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'multinomial', 'pe...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.900</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.779</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.820</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.883</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.884</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'squared_hinge', 'pena...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0  RandomForestClassifier     0.842                0.867             0.840   \n",
       "1      LogisticRegression     0.900                0.903             0.900   \n",
       "2                     SVC     0.900                0.901             0.899   \n",
       "3  DecisionTreeClassifier     0.783                0.785             0.780   \n",
       "4           MultinomialNB     0.825                0.836             0.826   \n",
       "5           MLPClassifier     0.883                0.886             0.882   \n",
       "6           SGDClassifier     0.883                0.888             0.884   \n",
       "\n",
       "   macro avg_f1-score                                        best_params  \\\n",
       "0               0.843  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "1               0.900  {'C': 100.0, 'multi_class': 'multinomial', 'pe...   \n",
       "2               0.900  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "3               0.779  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "4               0.820                                     {'alpha': 0.5}   \n",
       "5               0.883  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "6               0.884  {'alpha': 0.01, 'loss': 'squared_hinge', 'pena...   \n",
       "\n",
       "  Feature Selection  \n",
       "0      All features  \n",
       "1      All features  \n",
       "2      All features  \n",
       "3      All features  \n",
       "4      All features  \n",
       "5      All features  \n",
       "6      All features  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_uni = pd.DataFrame(report_uni)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "report_uni[columns_to_round] = report_uni[columns_to_round].apply(lambda x: round(x, 3))\n",
    "report_uni.to_csv(r'C:\\results\\report_uni.csv', index=False)\n",
    "report_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u2CvAH-tR3-O",
   "metadata": {
    "id": "u2CvAH-tR3-O"
   },
   "source": [
    "Finding maximum and minuímum accuracies in Chi2 & Mutual Info feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "V2mYAhF0j5dT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2mYAhF0j5dT",
    "outputId": "634472f8-0e21-4eba-83c0-d8dc9450e109"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Avg Precision</th>\n",
       "      <th>Macro Avg Recall</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.908</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.678</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.874</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.719</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.900</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.780</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy  Macro Avg Precision  Macro Avg Recall  \\\n",
       "0      LogisticRegression     0.908                0.912             0.908   \n",
       "1  DecisionTreeClassifier     0.683                0.683             0.678   \n",
       "2      LogisticRegression     0.875                0.881             0.874   \n",
       "3  DecisionTreeClassifier     0.717                0.718             0.719   \n",
       "4      LogisticRegression     0.900                0.903             0.900   \n",
       "5  DecisionTreeClassifier     0.783                0.785             0.780   \n",
       "\n",
       "  Feature Selection  \n",
       "0          chi2_800  \n",
       "1          chi2_800  \n",
       "2            mi_400  \n",
       "3           mi_1200  \n",
       "4      All features  \n",
       "5      All features  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_details(df, feature_name):\n",
    "    # Finding index of max and min accuracies\n",
    "    max_accuracy_index = df['accuracy'].idxmax()\n",
    "    min_accuracy_index = df['accuracy'].idxmin()\n",
    "    \n",
    "    # Extracting details for maximum accuracy\n",
    "    max_details = {\n",
    "        'Classifier': df.loc[max_accuracy_index, 'classifier'],\n",
    "        'Type': 'Highest',\n",
    "        'Accuracy': df.loc[max_accuracy_index, 'accuracy'],\n",
    "        'Macro Avg Precision': df.loc[max_accuracy_index, 'macro avg_precision'],\n",
    "        'Macro Avg Recall': df.loc[max_accuracy_index, 'macro avg_recall'],\n",
    "        'Feature Selection': df.loc[max_accuracy_index, 'Feature Selection']\n",
    "    }\n",
    "    \n",
    "    # Extracting details for minimum accuracy\n",
    "    min_details = {\n",
    "        'Classifier': df.loc[min_accuracy_index, 'classifier'],\n",
    "        'Type': 'Lowest',\n",
    "        'Accuracy': df.loc[min_accuracy_index, 'accuracy'],\n",
    "        'Macro Avg Precision': df.loc[min_accuracy_index, 'macro avg_precision'],\n",
    "        'Macro Avg Recall': df.loc[min_accuracy_index, 'macro avg_recall'],\n",
    "        'Feature Selection': df.loc[min_accuracy_index, 'Feature Selection']\n",
    "    }\n",
    "    \n",
    "    # Creating DataFrame from details with specific column order\n",
    "    results_df = pd.DataFrame([max_details, min_details], columns=[\n",
    "        'Classifier', 'Accuracy', 'Macro Avg Precision', 'Macro Avg Recall', 'Feature Selection'\n",
    "    ])\n",
    "    return results_df\n",
    "\n",
    "# Using the function and combining results\n",
    "results_chi2 = get_accuracy_details(merge_df_chi2, 'Chi2')\n",
    "results_mi = get_accuracy_details(merge_df_mi, 'Mutual Information')\n",
    "results_uni = get_accuracy_details(report_uni, 'Unfiltered')\n",
    "\n",
    "# Combining all results into a single DataFrame\n",
    "final_results = pd.concat([results_chi2, results_mi, results_uni], ignore_index=True)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "xUCRGPRzq6Ws",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "xUCRGPRzq6Ws",
    "outputId": "17d39cfa-6f64-47d5-be69-75595c8445b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(final_results['Classifier'], final_results['Accuracy'], color='blue')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Machine Learning Classifiers')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "VCFcVIqUfXuR",
   "metadata": {
    "id": "VCFcVIqUfXuR"
   },
   "outputs": [],
   "source": [
    "def load_model(file_path):\n",
    "    \"\"\"Helper function to load a model from a specified file path.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Define model and selector file paths\n",
    "logistic_regression_path = \"C:/Results/LogisticRegression_chi2_800.pkl\"\n",
    "chi2_selector_path = \"C:/Results/Selectors/selector_chi2_800.pkl\"\n",
    "decision_tree_path = \"C:/Results/DecisionTreeClassifier_uni.pkl\"\n",
    "vectorizer_path = \"C:/Results/Selectors/selector_uni.pkl\"\n",
    "\n",
    "# Load models and selectors using the helper function\n",
    "logistic_regression = load_model(logistic_regression_path)\n",
    "chi2_selector = load_model(chi2_selector_path)\n",
    "decision_tree = load_model(decision_tree_path)\n",
    "vectorizer = load_model(vectorizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee36a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class with decision tree: 0 Neutral\n",
      "Predicted class with Logistic Regression: [2] Religious Offensive\n"
     ]
    }
   ],
   "source": [
    "# Process new text data\n",
    "new_text = [\"tum jeson ko to ddob kar majana chaye\"]\n",
    "test_vector = vectorizer.transform(new_text)\n",
    "new_data_transformed = chi2_selector.transform(test_vector)\n",
    "\n",
    "# Make predictions using the Logistic Regression and Decision Tree models\n",
    "prediction_lr = logistic_regression.predict(new_data_transformed)\n",
    "prediction_dt = decision_tree.predict(test_vector)\n",
    "\n",
    "# Define a function to print the decision tree prediction\n",
    "def print_decision_tree_prediction(prediction):\n",
    "    if prediction == 0:\n",
    "        print(\"Predicted class with decision tree: 0 Neutral\")\n",
    "    elif prediction == 1:\n",
    "        print(\"Predicted class with decision tree: 1 Political Offensive\")\n",
    "    else:\n",
    "        print(\"Predicted class with decision tree:\", prediction, \"Religious Offensive\")\n",
    "\n",
    "# Define a function to print the logistic regression prediction\n",
    "def print_logistic_regression_prediction(prediction):\n",
    "    if prediction == 0:\n",
    "        print(\"Predicted class with Logistic Regression: 0 Neutral\")\n",
    "    elif prediction == 1:\n",
    "        print(\"Predicted class with Logistic Regression: 1 Political Offensive\")\n",
    "    else:\n",
    "        print(\"Predicted class with Logistic Regression:\", prediction, \"Religious Offensive\")\n",
    "\n",
    "# Call the print functions to display predictions\n",
    "print_decision_tree_prediction(prediction_dt)\n",
    "print_logistic_regression_prediction(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6128fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
