{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "n26igyz9T56e",
   "metadata": {
    "id": "n26igyz9T56e"
   },
   "source": [
    "Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "005d60ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "005d60ee",
    "outputId": "b66291f4-62bc-4713-b8c9-8753c0b6748f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\h.ahmed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os \n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC  # For SVM classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "OnFoKi8s8n3h",
   "metadata": {
    "id": "OnFoKi8s8n3h"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oUWLoWzxUsVZ",
   "metadata": {
    "id": "oUWLoWzxUsVZ"
   },
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ec312c6",
   "metadata": {
    "id": "8ec312c6"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:\\data\\RomanUrduDataset_WIP.csv\", usecols = [0,1], names = ['Sentence','Catagories'], encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de83dd6c",
   "metadata": {
    "id": "de83dd6c"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "905c46dc",
   "metadata": {
    "id": "905c46dc"
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d634f0ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d634f0ba",
    "outputId": "56e0b758-7f2b-48df-9ac0-b7b3d4e312dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catagories\n",
       "religious offensive    200\n",
       "political offensive    200\n",
       "Neutral                200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Catagories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2fb6e73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2fb6e73",
    "outputId": "02fca4f8-1605-4f33-fd8d-017974e91379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WeIek45pU2Gc",
   "metadata": {
    "id": "WeIek45pU2Gc"
   },
   "source": [
    "Data Pre-processing (Removing Punctuation, digits, special characters, white spaces, checking duplicates, converting to lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ipDTLc_C88Fx",
   "metadata": {
    "id": "ipDTLc_C88Fx"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(sentence):\n",
    "    # Convert each sentence to lowercase\n",
    "    sentence = sentence.str.lower()\n",
    "     # Remove non-ASCII characters\n",
    "    sentence = sentence.str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    # Remove dots, punctuations, digits, and special characters\n",
    "    sentence = sentence.str.replace(r'[^\\w\\s]', '')\n",
    "    # Remove emoticons like :) :D :p :o\n",
    "    sentence = sentence.str.replace(r'[:;][\\)\\(dpo*]', '')\n",
    "    sentence = sentence.str.replace(r'([^\\w\\s]|_)+(?=\\s|$)', '')\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^\\W.*', '', word) for word in x.split()]))\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^\\W+|\\W+$', '', word) for word in x.split()]))\n",
    "    # sentence = sentence.apply(lambda x: ' '.join([re.sub(r'^[^\\w\\s]+|[^\\w\\s]+$', '', word) for word in x.split()]))\n",
    "    sentence = sentence.apply(lambda x: ' '.join([re.sub(r'([^\\w\\s]|_)+(?=\\s|$)', '', word) for word in x.split()]))\n",
    "\n",
    "    # Remove specific special characters like question marks\n",
    "    sentence = sentence.str.replace(r'\\?+', '')\n",
    "    # Remove big words with length more than 10 characters\n",
    "    sentence = sentence.apply(lambda x: ' '.join([word for word in x.split() if len(word) <= 10]))\n",
    "    # Remove duplicate words in each sentence\n",
    "    sentence = sentence.apply(lambda x: ' '.join(sorted(set(x.split()), key=x.split().index)))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cca52735",
   "metadata": {
    "id": "cca52735"
   },
   "outputs": [],
   "source": [
    "# def data_preprocessing(ru_text):\n",
    "#     ru_text = ru_text.astype(str).str.lower()\n",
    "#     ru_text = ru_text.astype(str).str.replace('[{}]'.format(string.punctuation), '')\n",
    "#     ru_text = ru_text.astype(str).str.replace(\"[^a-zA-Z#]\",' ')\n",
    "#     ru_text = ru_text.apply(lambda x: ' '.join([word for word in str(x).split() if not word.isdigit()]))\n",
    "#     ru_text = ru_text.astype(str).str.strip()\n",
    "#     return ru_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae923c2e",
   "metadata": {
    "id": "ae923c2e"
   },
   "outputs": [],
   "source": [
    "dataset.replace('', np.nan, inplace = True)\n",
    "dataset.dropna(inplace=True)\n",
    "dataset['Sentence'] = data_preprocessing(dataset['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "KDAdr-rF7jdU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "KDAdr-rF7jdU",
    "outputId": "b3c9664a-a28a-4656-87c0-da4b8333320d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive\n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive\n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive\n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive\n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive\n",
       "..                                                 ...                  ...\n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral\n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral\n",
       "598                              g m asaa kuch nh khti              Neutral\n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral\n",
       "600                               main apka btaou janu              Neutral\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "WV79B3N0DfFc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "WV79B3N0DfFc",
    "outputId": "72f11e64-4481-4467-d5f9-332f758cfc02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "dataset.groupby('Catagories').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f67007bb",
   "metadata": {
    "id": "f67007bb"
   },
   "outputs": [],
   "source": [
    "#sent = dataset[\"Sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ad12a0b",
   "metadata": {
    "id": "1ad12a0b"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['Sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzTGDORTW478",
   "metadata": {
    "id": "tzTGDORTW478"
   },
   "source": [
    "Data Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67b288aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "67b288aa",
    "outputId": "e9553272-0ef8-42f2-97cd-259d682f5538"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ecbf4b9",
   "metadata": {
    "id": "7ecbf4b9"
   },
   "outputs": [],
   "source": [
    "with open (\"C:/data/ru_words.json\") as f:\n",
    "    ru_words = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7e9ffe7",
   "metadata": {
    "id": "d7e9ffe7"
   },
   "outputs": [],
   "source": [
    "def Lema(variations,token_sent):\n",
    "  sents = token_sent.copy()\n",
    "  lematized = []\n",
    "  replacements = variations.keys()\n",
    "  for i,tokens in enumerate(sents):\n",
    "    for j,token in enumerate(tokens):\n",
    "      if token in replacements:\n",
    "        #print(f\"Original  {token} with {variations[token]} on index {i}\")\n",
    "        tokens[j] = variations[token]\n",
    "    #print(tokens)\n",
    "    lematized.append(tokens)\n",
    "  return lematized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "iQxYzt-8HMbE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQxYzt-8HMbE",
    "outputId": "678e1a1a-aa8a-4457-9cc8-978c4a941498"
   },
   "outputs": [],
   "source": [
    "token_sent = Lema(ru_words[\"ru_words\"],dataset[\"lematized_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f0xRim3JCshc",
   "metadata": {
    "id": "f0xRim3JCshc"
   },
   "outputs": [],
   "source": [
    "dataset['tokenized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['Sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "-D_CawTdFoz4",
   "metadata": {
    "id": "-D_CawTdFoz4"
   },
   "outputs": [],
   "source": [
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5sQEAEIJRCWE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5sQEAEIJRCWE",
    "outputId": "3fa7ef62-d399-4e73-b643-90e02f74e59e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sare, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nahi, khti]</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...   \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]   \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...   \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...   \n",
       "5    [sare, shia, jahil, hain, in, ky, belief, ki, ...   \n",
       "..                                                 ...   \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...   \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...   \n",
       "598                     [g, m, asaa, kuch, nahi, khti]   \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...   \n",
       "600                          [main, apka, btaou, janu]   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "qJl0yK7DMqCl",
   "metadata": {
    "id": "qJl0yK7DMqCl"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset['lematized_sent'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "gwlkObzGMxtA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gwlkObzGMxtA",
    "outputId": "30ec570c-ae6c-44f9-9a8a-a7206807e366"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>sare shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g m asaa kuch nahi khti</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...   \n",
       "2                       qadyani ka jo yaar hai ghaddar   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...   \n",
       "5           sare shia jahil hain in ky belief ki tarha   \n",
       "..                                                 ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...   \n",
       "598                            g m asaa kuch nahi khti   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy   \n",
       "600                               main apka btaou janu   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPUALPkNPqH4",
   "metadata": {
    "id": "LPUALPkNPqH4"
   },
   "source": [
    "Saving Dataset for Target Group Identification (task 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "s0_EkIQPP3qT",
   "metadata": {
    "id": "s0_EkIQPP3qT"
   },
   "outputs": [],
   "source": [
    "copy_data = dataset[['lematized_sent','Catagories']]\n",
    "copy_data.to_csv(r'C:\\results\\task_02_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "C-paFIc9QyHE",
   "metadata": {
    "id": "C-paFIc9QyHE"
   },
   "outputs": [],
   "source": [
    "# read_back_data = pd.read_csv(('/content/drive/MyDrive/Thesis_Data/Group_identification_data.csv'),index_col=0)\n",
    "# read_back_data\n",
    "# read_back_data = copy_data.copy()\n",
    "# read_back_data = read_back_data.set_index(read_back_data.columns[0])\n",
    "# read_back_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nJ2Ezv7XGeS",
   "metadata": {
    "id": "0nJ2Ezv7XGeS"
   },
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "jRjUfQhpM7rv",
   "metadata": {
    "id": "jRjUfQhpM7rv"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = dataset.apply(lambda row: nltk.word_tokenize(row['lematized_sent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "_rxpjeMANd4u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_rxpjeMANd4u",
    "outputId": "28db72c4-6ad0-4fdf-c2b2-b4dcfe96a084"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>[sare, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, m, asaa, kuch, nahi, khti]</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...   \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]   \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...   \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...   \n",
       "5    [sare, shia, jahil, hain, in, ky, belief, ki, ...   \n",
       "..                                                 ...   \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...   \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...   \n",
       "598                     [g, m, asaa, kuch, nahi, khti]   \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...   \n",
       "600                          [main, apka, btaou, janu]   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "YIM-LBy0J_iq",
   "metadata": {
    "id": "YIM-LBy0J_iq"
   },
   "outputs": [],
   "source": [
    "ru_stopwords =  ['ai', 'ayi', 'hy', 'hai', 'main', 'ki', 'tha', 'koi', 'ko', 'sy', 'woh ', 'bhi',\n",
    "                 'aur', 'wo', 'yeh', 'rha', 'hota', 'ho', 'ga', 'ka', 'le', 'lye ', 'kr', 'kar',\n",
    "                 'lye', 'liye', 'hotay', 'waisay', 'gya', 'gaya', 'kch', 'ab', 'thy', 'thay', 'houn',\n",
    "                 'hain', 'han', 'to', 'is', 'hi', 'jo', 'kya', 'thi', 'se', 'pe', 'phr', 'wala', 'waisay',\n",
    "                 'us', 'na', 'ny', 'hun', 'rha', 'raha', 'ja', 'rahay', 'abi', 'uski', 'ne', 'haan', 'acha',\n",
    "                 'nai', 'sent', 'you', 'kafi', 'gai', 'rhy', 'kuch', 'jata', 'aye', 'ya', 'dono', 'hoa',\n",
    "                 'aese', 'de', 'wohi', 'jati', 'jb', 'krta', 'lg', 'rahi', 'hui', 'karna', 'krna', 'gi', 'hova',\n",
    "                 'yehi', 'jana', 'jye', 'chal', 'mil', 'tu', 'hum', 'par', 'hay', 'kis', 'sb', 'gy', 'dain', 'krny', 'tou',\n",
    "                 'hn', 'rahe','karo','kro','kia','don','kha', 'aap','aby','agya','ap','app','aray','ary','ata','atay','ati','bd',\n",
    "\t\t\t\t         'bna','da','di','ek','esa','ge','ha','hmy','hon','hoti','hoty','hue','hue','huy','iss','jay','jaye','je','ji',\n",
    "                 'karta','karte','karty','ky','liya','mn','mlti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hYSuA5CeLVq2",
   "metadata": {
    "id": "hYSuA5CeLVq2"
   },
   "outputs": [],
   "source": [
    "def stopwords_removal(ru_text):\n",
    "  ru_text = ru_text.apply(lambda x: ' '.join([word for word in str(x).split() if not word in ru_stopwords]))\n",
    "  return ru_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cIUE2sjoL--F",
   "metadata": {
    "id": "cIUE2sjoL--F"
   },
   "outputs": [],
   "source": [
    "dataset['lematized_sent'] = stopwords_removal(dataset['lematized_sent'].str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "p1puuXKDZoz-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "p1puuXKDZoz-",
    "outputId": "d3542625-267b-48ea-b8c1-113349b60db1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Catagories</th>\n",
       "      <th>lematized_sent</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aj ek shia se mila mene us pocha k tum log zul...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>aj shia mila mene pocha k tum log zuljana tatt...</td>\n",
       "      <td>[aj, ek, shia, se, mila, mene, us, pocha, k, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qadyani ka jo yaar hai ghaddar</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>qadyani yaar ghaddar</td>\n",
       "      <td>[qadyani, ka, jo, yaar, hai, ghaddar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aby jaa khatmal tum sare mutah ki paidawar ho</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>jaa khatmal tum sare mutah paidawar</td>\n",
       "      <td>[aby, jaa, khatmal, tum, sare, mutah, ki, paid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirza qadyani aur is ki zaryat ke kafir honay ...</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>mirza qadyani zaryat ke kafir honay mein shak ...</td>\n",
       "      <td>[mirza, qadyani, aur, is, ki, zaryat, ke, kafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sary shia jahil hain in ky belief ki tarha</td>\n",
       "      <td>religious offensive</td>\n",
       "      <td>sare shia jahil in belief tarha</td>\n",
       "      <td>[sary, shia, jahil, hain, in, ky, belief, ki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bhai ye kia sun raha hun is ka matlb me bilkul...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai ye sun matlb me bilkul thek kehta</td>\n",
       "      <td>[bhai, ye, kia, sun, raha, hun, is, ka, matlb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>bhai dunya gol ha kisi na tariqe se ye bat sam...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>bhai dunya gol kisi tariqe ye bat samne ani</td>\n",
       "      <td>[bhai, dunya, gol, ha, kisi, na, tariqe, se, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>g m asaa kuch nh khti</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g m asaa nahi khti</td>\n",
       "      <td>[g, m, asaa, kuch, nh, khti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>g apne friday ko e ye alfaz milahaza fermae thy</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>g apne friday e ye alfaz milahaza fermae</td>\n",
       "      <td>[g, apne, friday, ko, e, ye, alfaz, milahaza, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>main apka btaou janu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>apka btaou janu</td>\n",
       "      <td>[main, apka, btaou, janu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence           Catagories  \\\n",
       "1    aj ek shia se mila mene us pocha k tum log zul...  religious offensive   \n",
       "2                       qadyani ka jo yaar hai ghaddar  religious offensive   \n",
       "3        aby jaa khatmal tum sare mutah ki paidawar ho  religious offensive   \n",
       "4    mirza qadyani aur is ki zaryat ke kafir honay ...  religious offensive   \n",
       "5           sary shia jahil hain in ky belief ki tarha  religious offensive   \n",
       "..                                                 ...                  ...   \n",
       "596  bhai ye kia sun raha hun is ka matlb me bilkul...              Neutral   \n",
       "597  bhai dunya gol ha kisi na tariqe se ye bat sam...              Neutral   \n",
       "598                              g m asaa kuch nh khti              Neutral   \n",
       "599    g apne friday ko e ye alfaz milahaza fermae thy              Neutral   \n",
       "600                               main apka btaou janu              Neutral   \n",
       "\n",
       "                                        lematized_sent  \\\n",
       "1    aj shia mila mene pocha k tum log zuljana tatt...   \n",
       "2                                 qadyani yaar ghaddar   \n",
       "3                  jaa khatmal tum sare mutah paidawar   \n",
       "4    mirza qadyani zaryat ke kafir honay mein shak ...   \n",
       "5                      sare shia jahil in belief tarha   \n",
       "..                                                 ...   \n",
       "596             bhai ye sun matlb me bilkul thek kehta   \n",
       "597        bhai dunya gol kisi tariqe ye bat samne ani   \n",
       "598                                 g m asaa nahi khti   \n",
       "599           g apne friday e ye alfaz milahaza fermae   \n",
       "600                                    apka btaou janu   \n",
       "\n",
       "                                        tokenized_sent  \n",
       "1    [aj, ek, shia, se, mila, mene, us, pocha, k, t...  \n",
       "2                [qadyani, ka, jo, yaar, hai, ghaddar]  \n",
       "3    [aby, jaa, khatmal, tum, sare, mutah, ki, paid...  \n",
       "4    [mirza, qadyani, aur, is, ki, zaryat, ke, kafi...  \n",
       "5    [sary, shia, jahil, hain, in, ky, belief, ki, ...  \n",
       "..                                                 ...  \n",
       "596  [bhai, ye, kia, sun, raha, hun, is, ka, matlb,...  \n",
       "597  [bhai, dunya, gol, ha, kisi, na, tariqe, se, y...  \n",
       "598                       [g, m, asaa, kuch, nh, khti]  \n",
       "599  [g, apne, friday, ko, e, ye, alfaz, milahaza, ...  \n",
       "600                          [main, apka, btaou, janu]  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "Aizy1p4PMdO2",
   "metadata": {
    "id": "Aizy1p4PMdO2"
   },
   "outputs": [],
   "source": [
    "temp_data = dataset[['lematized_sent','Catagories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Z2Q2Rf9Mc2B",
   "metadata": {
    "id": "5Z2Q2Rf9Mc2B"
   },
   "source": [
    "Spliting dataset traning 80% testing 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ja98kGAHMDZz",
   "metadata": {
    "id": "ja98kGAHMDZz"
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "X = temp_data['lematized_sent']\n",
    "y = labelencoder.fit_transform(temp_data['Catagories'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2V_oeelwPnRe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V_oeelwPnRe",
    "outputId": "ab10d61b-bece-4845-eed8-7255ff657d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Neutral', 2: 'religious offensive', 1: 'political offensive'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = list(set([categories for _, categories in enumerate(zip(temp_data['Catagories'], y.tolist()))]))\n",
    "# categories = dict(categories)\n",
    "categories = dict([(index, category) for category, index in categories])\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFMh4hsGLjog",
   "metadata": {
    "id": "XFMh4hsGLjog"
   },
   "source": [
    "Initialze N-gram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "X5NxC9iUC3sE",
   "metadata": {
    "id": "X5NxC9iUC3sE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer_uni = TfidfVectorizer()\n",
    "\n",
    "vectorizer_uni.fit(X_train)\n",
    "\n",
    "X_train_uni, X_test_uni = vectorizer_uni.transform(X_train), vectorizer_uni.transform(X_test)\n",
    "\n",
    "print(type(vectorizer_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7m_1rZvqOK0",
   "metadata": {
    "id": "I7m_1rZvqOK0"
   },
   "source": [
    "Testing Feature selection (Mutual Info & Chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "SzGkWoMraaeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzGkWoMraaeq",
    "outputId": "ce6c3ddf-bff3-4a19-cb94-bf3793ce3690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 1619), (120,), (120,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_uni.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "DCWm9-MFCr7U",
   "metadata": {
    "id": "DCWm9-MFCr7U"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def select_features(selection_method, k, X_train, y_train, X_test):\n",
    "    \"\"\"Applies feature selection and returns the selector along with transformed training and testing data.\"\"\"\n",
    "    selector = SelectKBest(selection_method, k=k)\n",
    "    X_train_transformed = selector.fit_transform(X_train, y_train)\n",
    "    X_test_transformed = selector.transform(X_test)\n",
    "    return selector, X_train_transformed, X_test_transformed\n",
    "\n",
    "# Define number of features for different selections\n",
    "feature_numbers = [400, 800, 1200]\n",
    "\n",
    "# Initialize a dictionary to store training and testing datasets\n",
    "train_set = {}\n",
    "\n",
    "\n",
    "# Apply feature selection for Chi-square\n",
    "for k in feature_numbers:\n",
    "    selector_chi, X_train_chi, X_test_chi = select_features(chi2, k, X_train_uni, y_train, X_test_uni)\n",
    "    train_set[f\"chi2_{k}\"] = {\n",
    "        \"selector\": selector_chi,\n",
    "        \"train\": X_train_chi,\n",
    "        \"test\": X_test_chi\n",
    "    }\n",
    "\n",
    "# Apply feature selection for Mutual Information\n",
    "for k in feature_numbers:\n",
    "    selector_mi, X_train_mi, X_test_mi = select_features(mutual_info_classif, k, X_train_uni, y_train, X_test_uni)\n",
    "    train_set[f\"mi_{k}\"] = {\n",
    "        \"selector\": selector_mi,\n",
    "        \"train\": X_train_mi,\n",
    "        \"test\": X_test_mi\n",
    "    }\n",
    "\n",
    "# Include unfiltered features as well\n",
    "# Assuming there is a basic selector or process for 'uni' that you might want to keep track of (even if it's just identity)\n",
    "train_set[\"uni\"] = {\n",
    "    \"selector\": vectorizer_uni,  # or an identity/select-all selector if applicable\n",
    "    \"train\": X_train_uni,\n",
    "    \"test\": X_test_uni\n",
    "}\n",
    "\n",
    "### Saving the selctors###\n",
    "base_path = \"C:\\\\Results\\\\Selectors\"\n",
    "# Ensure the directory exists; if not, create it\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "for key, value in train_set.items():\n",
    "    if value[\"selector\"] is not None:\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(base_path, f'selector_{key}.pkl')\n",
    "        \n",
    "        # Save the selector to the file\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(value[\"selector\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1f4670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_400\n",
      "  (0, 388)\t0.3431510931988059\n",
      "  (0, 307)\t0.345788434434944\n",
      "  (0, 265)\t0.5182577064957191\n",
      "  (0, 198)\t0.49056631238126797\n",
      "  (0, 190)\t0.503419634760044\n",
      "  (1, 328)\t0.3892813329205754\n",
      "  (1, 207)\t0.2283544531051882\n",
      "  (1, 197)\t0.3264538688523205\n",
      "  (2, 388)\t0.24143344129228228\n",
      "  (2, 377)\t0.34515149544243506\n",
      "  (2, 305)\t0.33717473034061024\n",
      "  (2, 227)\t0.3920943527860786\n",
      "  (2, 195)\t0.41157739890698797\n",
      "  (2, 102)\t0.3920943527860786\n",
      "  (3, 304)\t0.6439696849245412\n",
      "  (3, 269)\t0.7650510080368413\n",
      "  (4, 257)\t0.25019636316941485\n",
      "  (4, 26)\t0.3059275437717956\n",
      "  (4, 23)\t0.34531249337969183\n",
      "  (5, 368)\t0.43286842010469856\n",
      "  (5, 220)\t0.4805704809666063\n",
      "  (5, 84)\t0.7626774834093286\n",
      "  (6, 367)\t0.6213933333379952\n",
      "  (6, 211)\t0.6213933333379952\n",
      "  (6, 31)\t0.4772218043700333\n",
      "  :\t:\n",
      "  (470, 341)\t0.29843917921162844\n",
      "  (470, 268)\t0.30625858075643553\n",
      "  (470, 262)\t0.17142259141095437\n",
      "  (470, 181)\t0.32596189901822253\n",
      "  (471, 333)\t0.2484417152719478\n",
      "  (472, 300)\t0.5978718910411236\n",
      "  (472, 138)\t0.5978718910411236\n",
      "  (473, 275)\t0.351390987964331\n",
      "  (473, 257)\t0.25460053987248443\n",
      "  (473, 205)\t0.351390987964331\n",
      "  (473, 152)\t0.25460053987248443\n",
      "  (474, 265)\t0.4712993777711736\n",
      "  (474, 255)\t0.5674667108206044\n",
      "  (474, 198)\t0.44611704733560104\n",
      "  (474, 95)\t0.5067918790781026\n",
      "  (475, 307)\t0.416567333480062\n",
      "  (475, 207)\t0.4133901589513351\n",
      "  (475, 151)\t0.7047161546645925\n",
      "  (477, 219)\t0.32633393740397065\n",
      "  (477, 200)\t0.3648614535459963\n",
      "  (477, 161)\t0.37948779212868394\n",
      "  (478, 149)\t0.22159366283615334\n",
      "  (478, 59)\t0.17769345715437915\n",
      "  (478, 10)\t0.18153519534937598\n",
      "  (478, 3)\t0.17769345715437915\n",
      "chi2_800\n",
      "  (0, 783)\t0.3431510931988059\n",
      "  (0, 623)\t0.345788434434944\n",
      "  (0, 537)\t0.5182577064957191\n",
      "  (0, 404)\t0.49056631238126797\n",
      "  (0, 396)\t0.503419634760044\n",
      "  (1, 787)\t0.4152535849026359\n",
      "  (1, 663)\t0.3892813329205754\n",
      "  (1, 423)\t0.2283544531051882\n",
      "  (1, 403)\t0.3264538688523205\n",
      "  (1, 301)\t0.4152535849026359\n",
      "  (1, 97)\t0.4152535849026359\n",
      "  (1, 81)\t0.4152535849026359\n",
      "  (2, 783)\t0.24143344129228228\n",
      "  (2, 764)\t0.34515149544243506\n",
      "  (2, 620)\t0.33717473034061024\n",
      "  (2, 572)\t0.27979213728786234\n",
      "  (2, 460)\t0.3920943527860786\n",
      "  (2, 401)\t0.41157739890698797\n",
      "  (2, 221)\t0.3920943527860786\n",
      "  (3, 619)\t0.6439696849245412\n",
      "  (3, 547)\t0.7650510080368413\n",
      "  (4, 523)\t0.25019636316941485\n",
      "  (4, 293)\t0.25019636316941485\n",
      "  (4, 61)\t0.3059275437717956\n",
      "  (4, 47)\t0.34531249337969183\n",
      "  :\t:\n",
      "  (474, 537)\t0.4712993777711736\n",
      "  (474, 518)\t0.5674667108206044\n",
      "  (474, 404)\t0.44611704733560104\n",
      "  (474, 205)\t0.5067918790781026\n",
      "  (475, 623)\t0.416567333480062\n",
      "  (475, 423)\t0.4133901589513351\n",
      "  (475, 312)\t0.7047161546645925\n",
      "  (476, 528)\t0.5013203295453942\n",
      "  (476, 234)\t0.5013203295453942\n",
      "  (476, 143)\t0.5013203295453942\n",
      "  (477, 738)\t0.3648614535459963\n",
      "  (477, 448)\t0.32633393740397065\n",
      "  (477, 410)\t0.3648614535459963\n",
      "  (477, 340)\t0.37948779212868394\n",
      "  (477, 34)\t0.4249213495440601\n",
      "  (478, 515)\t0.22159366283615334\n",
      "  (478, 309)\t0.22159366283615334\n",
      "  (478, 123)\t0.17769345715437915\n",
      "  (478, 33)\t0.20296753617426183\n",
      "  (478, 27)\t0.18153519534937598\n",
      "  (478, 13)\t0.17769345715437915\n",
      "  (479, 616)\t0.4504780401896615\n",
      "  (479, 322)\t0.4504780401896615\n",
      "  (479, 26)\t0.40231190326741934\n",
      "  (479, 18)\t0.4504780401896615\n",
      "chi2_1200\n",
      "  (0, 1170)\t0.3431510931988059\n",
      "  (0, 934)\t0.345788434434944\n",
      "  (0, 818)\t0.5182577064957191\n",
      "  (0, 605)\t0.49056631238126797\n",
      "  (0, 592)\t0.503419634760044\n",
      "  (1, 1180)\t0.4152535849026359\n",
      "  (1, 998)\t0.3892813329205754\n",
      "  (1, 639)\t0.2283544531051882\n",
      "  (1, 603)\t0.3264538688523205\n",
      "  (1, 465)\t0.4152535849026359\n",
      "  (1, 146)\t0.4152535849026359\n",
      "  (1, 124)\t0.4152535849026359\n",
      "  (2, 1170)\t0.24143344129228228\n",
      "  (2, 1149)\t0.34515149544243506\n",
      "  (2, 929)\t0.33717473034061024\n",
      "  (2, 865)\t0.27979213728786234\n",
      "  (2, 699)\t0.3920943527860786\n",
      "  (2, 601)\t0.41157739890698797\n",
      "  (2, 339)\t0.3920943527860786\n",
      "  (3, 928)\t0.6439696849245412\n",
      "  (3, 830)\t0.7650510080368413\n",
      "  (4, 1147)\t0.3683512119931035\n",
      "  (4, 911)\t0.3683512119931035\n",
      "  (4, 843)\t0.3683512119931035\n",
      "  (4, 794)\t0.25019636316941485\n",
      "  :\t:\n",
      "  (474, 786)\t0.5674667108206044\n",
      "  (474, 605)\t0.44611704733560104\n",
      "  (474, 317)\t0.5067918790781026\n",
      "  (475, 934)\t0.416567333480062\n",
      "  (475, 639)\t0.4133901589513351\n",
      "  (475, 479)\t0.7047161546645925\n",
      "  (476, 803)\t0.5013203295453942\n",
      "  (476, 361)\t0.5013203295453942\n",
      "  (476, 228)\t0.5013203295453942\n",
      "  (477, 1110)\t0.3648614535459963\n",
      "  (477, 680)\t0.32633393740397065\n",
      "  (477, 641)\t0.37948779212868394\n",
      "  (477, 614)\t0.3648614535459963\n",
      "  (477, 514)\t0.37948779212868394\n",
      "  (477, 48)\t0.4249213495440601\n",
      "  (478, 783)\t0.22159366283615334\n",
      "  (478, 476)\t0.22159366283615334\n",
      "  (478, 186)\t0.17769345715437915\n",
      "  (478, 46)\t0.20296753617426183\n",
      "  (478, 40)\t0.18153519534937598\n",
      "  (478, 22)\t0.17769345715437915\n",
      "  (479, 925)\t0.4504780401896615\n",
      "  (479, 489)\t0.4504780401896615\n",
      "  (479, 39)\t0.40231190326741934\n",
      "  (479, 27)\t0.4504780401896615\n",
      "mi_400\n",
      "  (0, 390)\t0.3431510931988059\n",
      "  (0, 305)\t0.345788434434944\n",
      "  (0, 265)\t0.5182577064957191\n",
      "  (0, 189)\t0.49056631238126797\n",
      "  (0, 184)\t0.503419634760044\n",
      "  (1, 322)\t0.3892813329205754\n",
      "  (1, 204)\t0.2283544531051882\n",
      "  (1, 188)\t0.3264538688523205\n",
      "  (2, 390)\t0.24143344129228228\n",
      "  (2, 381)\t0.34515149544243506\n",
      "  (2, 303)\t0.33717473034061024\n",
      "  (2, 281)\t0.27979213728786234\n",
      "  (2, 223)\t0.3920943527860786\n",
      "  (2, 119)\t0.3920943527860786\n",
      "  (2, 103)\t0.3920943527860786\n",
      "  (3, 302)\t0.6439696849245412\n",
      "  (3, 269)\t0.7650510080368413\n",
      "  (4, 259)\t0.25019636316941485\n",
      "  (4, 142)\t0.34531249337969183\n",
      "  (4, 139)\t0.25019636316941485\n",
      "  (4, 29)\t0.3059275437717956\n",
      "  (4, 22)\t0.34531249337969183\n",
      "  (5, 370)\t0.43286842010469856\n",
      "  (5, 215)\t0.4805704809666063\n",
      "  (6, 36)\t0.4772218043700333\n",
      "  :\t:\n",
      "  (475, 204)\t0.4133901589513351\n",
      "  (475, 176)\t0.39869207982382987\n",
      "  (475, 153)\t0.7047161546645925\n",
      "  (476, 238)\t0.24644737483343024\n",
      "  (476, 131)\t0.4304619297814882\n",
      "  (477, 368)\t0.3648614535459963\n",
      "  (477, 214)\t0.32633393740397065\n",
      "  (477, 205)\t0.37948779212868394\n",
      "  (477, 193)\t0.3648614535459963\n",
      "  (477, 163)\t0.37948779212868394\n",
      "  (477, 98)\t0.39834442218170346\n",
      "  (478, 345)\t0.22159366283615334\n",
      "  (478, 256)\t0.22159366283615334\n",
      "  (478, 238)\t0.11620264884271594\n",
      "  (478, 195)\t0.174218182229611\n",
      "  (478, 176)\t0.1253662736793302\n",
      "  (478, 151)\t0.22159366283615334\n",
      "  (478, 63)\t0.17769345715437915\n",
      "  (478, 15)\t0.20296753617426183\n",
      "  (478, 14)\t0.20296753617426183\n",
      "  (478, 12)\t0.18153519534937598\n",
      "  (478, 6)\t0.17769345715437915\n",
      "  (479, 304)\t0.33863973364771593\n",
      "  (479, 17)\t0.33863973364771593\n",
      "  (479, 10)\t0.40231190326741934\n",
      "mi_800\n",
      "  (0, 768)\t0.3431510931988059\n",
      "  (0, 611)\t0.345788434434944\n",
      "  (0, 539)\t0.5182577064957191\n",
      "  (0, 396)\t0.49056631238126797\n",
      "  (0, 387)\t0.503419634760044\n",
      "  (1, 776)\t0.4152535849026359\n",
      "  (1, 644)\t0.3892813329205754\n",
      "  (1, 426)\t0.2283544531051882\n",
      "  (1, 395)\t0.3264538688523205\n",
      "  (1, 292)\t0.4152535849026359\n",
      "  (1, 101)\t0.4152535849026359\n",
      "  (1, 89)\t0.4152535849026359\n",
      "  (2, 768)\t0.24143344129228228\n",
      "  (2, 753)\t0.34515149544243506\n",
      "  (2, 609)\t0.33717473034061024\n",
      "  (2, 568)\t0.27979213728786234\n",
      "  (2, 464)\t0.3920943527860786\n",
      "  (2, 393)\t0.41157739890698797\n",
      "  (2, 246)\t0.3920943527860786\n",
      "  (2, 210)\t0.3920943527860786\n",
      "  (3, 608)\t0.6439696849245412\n",
      "  (3, 547)\t0.7650510080368413\n",
      "  (4, 748)\t0.3683512119931035\n",
      "  (4, 599)\t0.3683512119931035\n",
      "  (4, 553)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (476, 222)\t0.5013203295453942\n",
      "  (476, 142)\t0.5013203295453942\n",
      "  (477, 721)\t0.3648614535459963\n",
      "  (477, 447)\t0.32633393740397065\n",
      "  (477, 427)\t0.37948779212868394\n",
      "  (477, 405)\t0.3648614535459963\n",
      "  (477, 339)\t0.37948779212868394\n",
      "  (477, 198)\t0.39834442218170346\n",
      "  (478, 677)\t0.22159366283615334\n",
      "  (478, 516)\t0.22159366283615334\n",
      "  (478, 489)\t0.11620264884271594\n",
      "  (478, 408)\t0.174218182229611\n",
      "  (478, 366)\t0.1253662736793302\n",
      "  (478, 304)\t0.22159366283615334\n",
      "  (478, 123)\t0.17769345715437915\n",
      "  (478, 32)\t0.20296753617426183\n",
      "  (478, 31)\t0.20296753617426183\n",
      "  (478, 29)\t0.18153519534937598\n",
      "  (478, 15)\t0.17769345715437915\n",
      "  (479, 610)\t0.33863973364771593\n",
      "  (479, 606)\t0.4504780401896615\n",
      "  (479, 317)\t0.4504780401896615\n",
      "  (479, 34)\t0.33863973364771593\n",
      "  (479, 27)\t0.40231190326741934\n",
      "  (479, 19)\t0.4504780401896615\n",
      "mi_1200\n",
      "  (0, 1167)\t0.3431510931988059\n",
      "  (0, 923)\t0.345788434434944\n",
      "  (0, 819)\t0.5182577064957191\n",
      "  (0, 598)\t0.49056631238126797\n",
      "  (0, 586)\t0.503419634760044\n",
      "  (1, 1176)\t0.4152535849026359\n",
      "  (1, 973)\t0.3892813329205754\n",
      "  (1, 637)\t0.2283544531051882\n",
      "  (1, 597)\t0.3264538688523205\n",
      "  (1, 445)\t0.4152535849026359\n",
      "  (1, 140)\t0.4152535849026359\n",
      "  (1, 125)\t0.4152535849026359\n",
      "  (2, 1167)\t0.24143344129228228\n",
      "  (2, 1142)\t0.34515149544243506\n",
      "  (2, 917)\t0.33717473034061024\n",
      "  (2, 859)\t0.27979213728786234\n",
      "  (2, 697)\t0.3920943527860786\n",
      "  (2, 595)\t0.41157739890698797\n",
      "  (2, 379)\t0.3920943527860786\n",
      "  (2, 322)\t0.3920943527860786\n",
      "  (3, 916)\t0.6439696849245412\n",
      "  (3, 829)\t0.7650510080368413\n",
      "  (4, 1137)\t0.3683512119931035\n",
      "  (4, 902)\t0.3683512119931035\n",
      "  (4, 836)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (478, 998)\t0.23637805130304798\n",
      "  (478, 883)\t0.23637805130304798\n",
      "  (478, 787)\t0.22159366283615334\n",
      "  (478, 742)\t0.11620264884271594\n",
      "  (478, 616)\t0.174218182229611\n",
      "  (478, 557)\t0.1253662736793302\n",
      "  (478, 462)\t0.22159366283615334\n",
      "  (478, 459)\t0.23637805130304798\n",
      "  (478, 350)\t0.23637805130304798\n",
      "  (478, 307)\t0.23637805130304798\n",
      "  (478, 250)\t0.23637805130304798\n",
      "  (478, 202)\t0.23637805130304798\n",
      "  (478, 183)\t0.23637805130304798\n",
      "  (478, 179)\t0.17769345715437915\n",
      "  (478, 44)\t0.20296753617426183\n",
      "  (478, 42)\t0.20296753617426183\n",
      "  (478, 36)\t0.18153519534937598\n",
      "  (478, 34)\t0.23637805130304798\n",
      "  (478, 15)\t0.17769345715437915\n",
      "  (479, 921)\t0.33863973364771593\n",
      "  (479, 913)\t0.4504780401896615\n",
      "  (479, 476)\t0.4504780401896615\n",
      "  (479, 46)\t0.33863973364771593\n",
      "  (479, 31)\t0.40231190326741934\n",
      "  (479, 20)\t0.4504780401896615\n",
      "uni\n",
      "  (0, 1582)\t0.3431510931988059\n",
      "  (0, 1243)\t0.345788434434944\n",
      "  (0, 1098)\t0.5182577064957191\n",
      "  (0, 803)\t0.49056631238126797\n",
      "  (0, 788)\t0.503419634760044\n",
      "  (1, 1592)\t0.4152535849026359\n",
      "  (1, 1325)\t0.3892813329205754\n",
      "  (1, 850)\t0.2283544531051882\n",
      "  (1, 801)\t0.3264538688523205\n",
      "  (1, 623)\t0.4152535849026359\n",
      "  (1, 200)\t0.4152535849026359\n",
      "  (1, 175)\t0.4152535849026359\n",
      "  (2, 1582)\t0.24143344129228228\n",
      "  (2, 1555)\t0.34515149544243506\n",
      "  (2, 1232)\t0.33717473034061024\n",
      "  (2, 1152)\t0.27979213728786234\n",
      "  (2, 933)\t0.3920943527860786\n",
      "  (2, 798)\t0.41157739890698797\n",
      "  (2, 535)\t0.3920943527860786\n",
      "  (2, 463)\t0.3920943527860786\n",
      "  (3, 1231)\t0.6439696849245412\n",
      "  (3, 1111)\t0.7650510080368413\n",
      "  (4, 1549)\t0.3683512119931035\n",
      "  (4, 1213)\t0.3683512119931035\n",
      "  (4, 1125)\t0.3683512119931035\n",
      "  :\t:\n",
      "  (478, 1356)\t0.23637805130304798\n",
      "  (478, 1184)\t0.23637805130304798\n",
      "  (478, 1052)\t0.22159366283615334\n",
      "  (478, 995)\t0.11620264884271594\n",
      "  (478, 825)\t0.174218182229611\n",
      "  (478, 755)\t0.1253662736793302\n",
      "  (478, 642)\t0.22159366283615334\n",
      "  (478, 639)\t0.23637805130304798\n",
      "  (478, 500)\t0.23637805130304798\n",
      "  (478, 443)\t0.23637805130304798\n",
      "  (478, 366)\t0.23637805130304798\n",
      "  (478, 293)\t0.23637805130304798\n",
      "  (478, 262)\t0.23637805130304798\n",
      "  (478, 256)\t0.17769345715437915\n",
      "  (478, 70)\t0.20296753617426183\n",
      "  (478, 68)\t0.20296753617426183\n",
      "  (478, 62)\t0.18153519534937598\n",
      "  (478, 60)\t0.23637805130304798\n",
      "  (478, 38)\t0.17769345715437915\n",
      "  (479, 1240)\t0.33863973364771593\n",
      "  (479, 1228)\t0.4504780401896615\n",
      "  (479, 659)\t0.4504780401896615\n",
      "  (479, 72)\t0.33863973364771593\n",
      "  (479, 57)\t0.40231190326741934\n",
      "  (479, 44)\t0.4504780401896615\n"
     ]
    }
   ],
   "source": [
    "for i, train_set_key in enumerate(train_set):\n",
    "         x_train=train_set.get(train_set_key)[\"train\"]\n",
    "         print(train_set_key)\n",
    "         print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aqT6lsq_4BEX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqT6lsq_4BEX",
    "outputId": "7a3c0436-0ad6-405e-8718-7069aa053ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UniGram features after TF-IDF transformation: 1619\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer_uni.get_feature_names_out()\n",
    "num_features = len(feature_names)\n",
    "\n",
    "print(f\"Number of UniGram features after TF-IDF transformation: {num_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hr34bTsVYLv9",
   "metadata": {
    "id": "Hr34bTsVYLv9"
   },
   "source": [
    "Implementing Machine Learning Classifiers: Random Forest, Logistic Regression, SVM, Decision Tree, Naive Bayes, MLP, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "na4oomxUHgIT",
   "metadata": {
    "id": "na4oomxUHgIT"
   },
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def parse_classification_report(report, best_params):\n",
    "    flat_report = flatten_dict(report)\n",
    "    flat_report['best_params'] = best_params  # Add 'best_params' information to the flattened report\n",
    "    df = pd.DataFrame.from_dict(flat_report, orient='index').transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "xkral1pwOGKO",
   "metadata": {
    "id": "xkral1pwOGKO"
   },
   "outputs": [],
   "source": [
    "classifier_properties = {\n",
    "    'random_forest': {'classifier': RandomForestClassifier(), 'param_grid_value': {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30], 'max_features': ['auto', 'sqrt', 'log2']}},\n",
    "    'logistic_regression': {'classifier': LogisticRegression(), 'param_grid_value': {\"C\": np.logspace(-3, 3, 7), \"penalty\": [\"l2\"],\"multi_class\": [\"ovr\", \"multinomial\"],}},\n",
    "    'svm_classifier': {\n",
    "        'classifier': SVC(),\n",
    "        'param_grid_value': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Different kernel functions\n",
    "            'decision_function_shape': ['ovr', 'ovo'],  # Decision function shape\n",
    "        }\n",
    "    },\n",
    "    'decision_tree': {'classifier': DecisionTreeClassifier(),\n",
    "        'param_grid_value': {\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 10, 20, 30],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "},\n",
    "    'nb_classifier': {'classifier': MultinomialNB(), 'param_grid_value': {'alpha': [0.1, 0.5, 1.0, 2.0]}},\n",
    "    'mlp_classifier': {'classifier': MLPClassifier(), 'param_grid_value': {'hidden_layer_sizes': [(50, 25), (100,)], 'activation': ['relu', 'tanh'], 'alpha': [0.0001, 0.001, 0.01]}},\n",
    "    'SGD_classifier': {'classifier': SGDClassifier(), 'param_grid_value': {'alpha': [0.0001, 0.001, 0.01, 0.1], 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge'], 'penalty': ['l2', 'l1', 'elasticnet']}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "P3kS6opRfwLu",
   "metadata": {
    "id": "P3kS6opRfwLu"
   },
   "outputs": [],
   "source": [
    "def classify(feature_name, classifier, x_train, y_train, x_test, y_test):\n",
    "  grid_search = GridSearchCV(classifier[\"classifier\"], classifier[\"param_grid_value\"], cv=7, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "  best_params = grid_search.best_params_\n",
    "  best_model = classifier[\"classifier\"].__class__(**best_params)\n",
    "  best_model.fit(x_train, y_train)\n",
    "\n",
    "  # Saving the classifeer...\n",
    "  folder_path = \"C:/Results\"\n",
    "  if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "  pickle_file_path = os.path.join(folder_path, f\"{classifier['classifier'].__class__.__name__}_{feature_name}.pkl\")\n",
    "  with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "  # Evaluate the model on the test dataset\n",
    "  y_pred = best_model.predict(x_test)\n",
    "  report = classification_report(y_test, y_pred, output_dict=True)\n",
    "  #print(classification_report(y_test, y_pred))\n",
    "  print(report)\n",
    "  accuracy = best_model.score(x_test, y_test)\n",
    "  print(f\"Test Set Accuracy: {accuracy:.2f}\")\n",
    "  print(best_params)\n",
    "\n",
    " # Save classification report to CSV file\n",
    "  reports.append({'classifier': classifier['classifier'].__class__.__name__, 'report': report, 'params': best_params})\n",
    "  dfs = []\n",
    "  for report in reports:\n",
    "     classifier_name = report['classifier']\n",
    "     classifier_report = parse_classification_report(report['report'],report['params'])\n",
    "     classifier_report['classifier'] = classifier_name\n",
    "     dfs.append(classifier_report)\n",
    "  combined_report = pd.concat(dfs)\n",
    "  file_path = \"C:/Results/combined_classification_report_\" + feature_name + \".csv\"\n",
    "  combined_report.to_csv(file_path, index=False)\n",
    "  print(f\"Combined classification report saved as 'combined_classification_report_{feature_name}.csv'\")\n",
    "\n",
    "\n",
    "  print(\"\\n\")\n",
    "\n",
    "\n",
    "  # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "  # print(\"Confusion Matrix:\")\n",
    "  # print(conf_matrix)\n",
    "  # print(\"\\n\")\n",
    "\n",
    "  # plt.figure(figsize=(5,5))\n",
    "  # sns.heatmap(conf_matrix, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "  # plt.ylabel('Actual label')\n",
    "  # plt.xlabel('Predicted label')\n",
    "  # plt.title('Confusion Matrix', size = 15)\n",
    "  # plt.show()\n",
    "  csv_file_path = os.path.join(folder_path, f\"{classifier['classifier']}_{feature_name}_MissClassified.csv\")\n",
    "  #print(\"Missclassified sentences and their labels\")\n",
    "  misclassified_indice_lables = [(i, true_label, pred_label) for i, (true_label, pred_label) in enumerate(zip(y_test, y_pred)) if true_label != pred_label]\n",
    "\n",
    "  missclassified_sentences = [(X_test.iloc[index], categories[true_label], categories[pred_label])  for (index, true_label, pred_label) in misclassified_indice_lables]\n",
    "  pd.DataFrame(missclassified_sentences, columns=[\"Sentence\", \"True Value\",  \"Predicted Value\"]).to_csv(csv_file_path, index=False)\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HjobL7l1YqVD",
   "metadata": {
    "id": "HjobL7l1YqVD"
   },
   "source": [
    "Classification with  CHi2 and Mutual Info Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "GIAWnLcwcfye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIAWnLcwcfye",
    "outputId": "c9a751a5-f2f8-4b8b-a3e3-779ffa55f275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_400\n",
      "chi2_800\n",
      "chi2_1200\n",
      "mi_400\n",
      "mi_800\n",
      "mi_1200\n",
      "uni\n"
     ]
    }
   ],
   "source": [
    "for a in train_set:\n",
    "  print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "YAqI797Do7ME",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAqI797Do7ME",
    "outputId": "450c15f2-d47c-4cc5-89bf-80acd2e2b961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.6949152542372882, 'recall': 1.0, 'f1-score': 0.82, 'support': 41.0}, '1': {'precision': 0.96, 'recall': 0.6666666666666666, 'f1-score': 0.7868852459016393, 'support': 36.0}, '2': {'precision': 1.0, 'recall': 0.8372093023255814, 'f1-score': 0.9113924050632911, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8849717514124293, 'recall': 0.834625322997416, 'f1-score': 0.8394258836549767, 'support': 120.0}, 'weighted avg': {'precision': 0.8837627118644068, 'recall': 0.8416666666666667, 'f1-score': 0.842814518918171, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8163265306122449, 'recall': 0.975609756097561, 'f1-score': 0.8888888888888888, 'support': 41.0}, '1': {'precision': 0.9375, 'recall': 0.8333333333333334, 'f1-score': 0.8823529411764706, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8923011512297228, 'recall': 0.8820507972521586, 'f1-score': 0.8830968701843881, 'support': 120.0}, 'weighted avg': {'precision': 0.8909307953950811, 'recall': 0.8833333333333333, 'f1-score': 0.8830437323981083, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8, 'recall': 0.975609756097561, 'f1-score': 0.8791208791208791, 'support': 41.0}, '1': {'precision': 0.9375, 'recall': 0.8333333333333334, 'f1-score': 0.8823529411764706, 'support': 36.0}, '2': {'precision': 0.9473684210526315, 'recall': 0.8372093023255814, 'f1-score': 0.8888888888888888, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8949561403508772, 'recall': 0.8820507972521586, 'f1-score': 0.8834542363954129, 'support': 120.0}, 'weighted avg': {'precision': 0.8940570175438597, 'recall': 0.8833333333333333, 'f1-score': 0.8835907012377601, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7058823529411765, 'recall': 0.8780487804878049, 'f1-score': 0.782608695652174, 'support': 41.0}, '1': {'precision': 0.9259259259259259, 'recall': 0.6944444444444444, 'f1-score': 0.7936507936507936, 'support': 36.0}, '2': {'precision': 0.8095238095238095, 'recall': 0.7906976744186046, 'f1-score': 0.8, 'support': 43.0}, 'accuracy': 0.7916666666666666, 'macro avg': {'precision': 0.8137773627969707, 'recall': 0.7877302997836181, 'f1-score': 0.7920864964343225, 'support': 120.0}, 'weighted avg': {'precision': 0.8090336134453782, 'recall': 0.7916666666666666, 'f1-score': 0.7921532091097309, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.79\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.4634146341463415, 'f1-score': 0.6031746031746031, 'support': 41.0}, '1': {'precision': 0.5789473684210527, 'recall': 0.9166666666666666, 'f1-score': 0.7096774193548387, 'support': 36.0}, '2': {'precision': 0.8780487804878049, 'recall': 0.8372093023255814, 'f1-score': 0.8571428571428571, 'support': 43.0}, 'accuracy': 0.7333333333333333, 'macro avg': {'precision': 0.7735441708484071, 'recall': 0.7390968677128632, 'f1-score': 0.723331626557433, 'support': 120.0}, 'weighted avg': {'precision': 0.7833941144435368, 'recall': 0.7333333333333333, 'f1-score': 0.7261307390339647, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.73\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.7916666666666666, 'recall': 0.926829268292683, 'f1-score': 0.8539325842696629, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.85, 'recall': 0.7906976744186046, 'f1-score': 0.8192771084337349, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8493055555555555, 'recall': 0.8410274994222812, 'f1-score': 0.842050289724662, 'support': 120.0}, 'weighted avg': {'precision': 0.8469444444444444, 'recall': 0.8416666666666667, 'f1-score': 0.8412169497553996, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8, 'recall': 0.975609756097561, 'f1-score': 0.8791208791208791, 'support': 41.0}, '1': {'precision': 0.9375, 'recall': 0.8333333333333334, 'f1-score': 0.8823529411764706, 'support': 36.0}, '2': {'precision': 0.9473684210526315, 'recall': 0.8372093023255814, 'f1-score': 0.8888888888888888, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8949561403508772, 'recall': 0.8820507972521586, 'f1-score': 0.8834542363954129, 'support': 120.0}, 'weighted avg': {'precision': 0.8940570175438597, 'recall': 0.8833333333333333, 'f1-score': 0.8835907012377601, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'alpha': 0.001, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7321428571428571, 'recall': 1.0, 'f1-score': 0.845360824742268, 'support': 41.0}, '1': {'precision': 0.9629629629629629, 'recall': 0.7222222222222222, 'f1-score': 0.8253968253968254, 'support': 36.0}, '2': {'precision': 0.972972972972973, 'recall': 0.8372093023255814, 'f1-score': 0.9, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.889359597692931, 'recall': 0.8531438415159346, 'f1-score': 0.8569192167130311, 'support': 120.0}, 'weighted avg': {'precision': 0.8876863470613471, 'recall': 0.8583333333333333, 'f1-score': 0.8589506627393225, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8666666666666667, 'recall': 0.9512195121951219, 'f1-score': 0.9069767441860465, 'support': 41.0}, '1': {'precision': 0.9428571428571428, 'recall': 0.9166666666666666, 'f1-score': 0.9295774647887324, 'support': 36.0}, '2': {'precision': 0.95, 'recall': 0.8837209302325582, 'f1-score': 0.9156626506024096, 'support': 43.0}, 'accuracy': 0.9166666666666666, 'macro avg': {'precision': 0.9198412698412698, 'recall': 0.9172023696981156, 'f1-score': 0.9174056198590628, 'support': 120.0}, 'weighted avg': {'precision': 0.9193849206349206, 'recall': 0.9166666666666666, 'f1-score': 0.9168694101660491, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.92\n",
      "{'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.7916666666666666, 'recall': 0.926829268292683, 'f1-score': 0.8539325842696629, 'support': 41.0}, '1': {'precision': 0.8787878787878788, 'recall': 0.8055555555555556, 'f1-score': 0.8405797101449275, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8645104895104895, 'recall': 0.8565313753912734, 'f1-score': 0.8575203583007984, 'support': 120.0}, 'weighted avg': {'precision': 0.8648917055167055, 'recall': 0.8583333333333333, 'f1-score': 0.85856835901041, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'linear'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.65, 'recall': 0.9512195121951219, 'f1-score': 0.7722772277227723, 'support': 41.0}, '1': {'precision': 0.8695652173913043, 'recall': 0.5555555555555556, 'f1-score': 0.6779661016949152, 'support': 36.0}, '2': {'precision': 0.918918918918919, 'recall': 0.7906976744186046, 'f1-score': 0.85, 'support': 43.0}, 'accuracy': 0.775, 'macro avg': {'precision': 0.8128280454367411, 'recall': 0.7658242473897606, 'f1-score': 0.7667477764725624, 'support': 120.0}, 'weighted avg': {'precision': 0.812232177830004, 'recall': 0.775, 'f1-score': 0.7718345499804218, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.896551724137931, 'recall': 0.6341463414634146, 'f1-score': 0.7428571428571429, 'support': 41.0}, '1': {'precision': 0.6739130434782609, 'recall': 0.8611111111111112, 'f1-score': 0.7560975609756098, 'support': 36.0}, '2': {'precision': 0.8666666666666667, 'recall': 0.9069767441860465, 'f1-score': 0.8863636363636364, 'support': 43.0}, 'accuracy': 0.8, 'macro avg': {'precision': 0.8123771447609528, 'recall': 0.800744732253524, 'f1-score': 0.7951061133987963, 'support': 120.0}, 'weighted avg': {'precision': 0.8190513076794936, 'recall': 0.8, 'f1-score': 0.7982524284658431, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.80\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8666666666666667, 'recall': 0.9512195121951219, 'f1-score': 0.9069767441860465, 'support': 41.0}, '1': {'precision': 0.9090909090909091, 'recall': 0.8333333333333334, 'f1-score': 0.8695652173913043, 'support': 36.0}, '2': {'precision': 0.9285714285714286, 'recall': 0.9069767441860465, 'f1-score': 0.9176470588235294, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.9014430014430014, 'recall': 0.8971765299048339, 'f1-score': 0.8980630068002934, 'support': 120.0}, 'weighted avg': {'precision': 0.901576479076479, 'recall': 0.9, 'f1-score': 0.8995768155593885, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8863636363636364, 'recall': 0.9512195121951219, 'f1-score': 0.9176470588235294, 'support': 41.0}, '1': {'precision': 0.9428571428571428, 'recall': 0.9166666666666666, 'f1-score': 0.9295774647887324, 'support': 36.0}, '2': {'precision': 0.9512195121951219, 'recall': 0.9069767441860465, 'f1-score': 0.9285714285714286, 'support': 43.0}, 'accuracy': 0.925, 'macro avg': {'precision': 0.9268134304719671, 'recall': 0.9249543076826116, 'f1-score': 0.9252653173945635, 'support': 120.0}, 'weighted avg': {'precision': 0.9265517104846375, 'recall': 0.925, 'f1-score': 0.9251407464394209, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.93\n",
      "{'alpha': 0.001, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7884615384615384, 'recall': 1.0, 'f1-score': 0.8817204301075269, 'support': 41.0}, '1': {'precision': 0.9310344827586207, 'recall': 0.75, 'f1-score': 0.8307692307692308, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8808576480990274, 'recall': 0.8624031007751939, 'f1-score': 0.8635128137881876, 'support': 120.0}, 'weighted avg': {'precision': 0.8794706012378426, 'recall': 0.8666666666666667, 'f1-score': 0.865119395858971, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8444444444444444, 'recall': 0.926829268292683, 'f1-score': 0.8837209302325582, 'support': 41.0}, '1': {'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1-score': 0.9166666666666666, 'support': 36.0}, '2': {'precision': 0.9487179487179487, 'recall': 0.8604651162790697, 'f1-score': 0.9024390243902439, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.9032763532763534, 'recall': 0.9013203504128064, 'f1-score': 0.9009422070964895, 'support': 120.0}, 'weighted avg': {'precision': 0.9034757834757835, 'recall': 0.9, 'f1-score': 0.9003119682359615, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'C': 10.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8085106382978723, 'recall': 0.926829268292683, 'f1-score': 0.8636363636363636, 'support': 41.0}, '1': {'precision': 0.9117647058823529, 'recall': 0.8611111111111112, 'f1-score': 0.8857142857142857, 'support': 36.0}, '2': {'precision': 0.9487179487179487, 'recall': 0.8604651162790697, 'f1-score': 0.9024390243902439, 'support': 43.0}, 'accuracy': 0.8833333333333333, 'macro avg': {'precision': 0.8896644309660579, 'recall': 0.882801831894288, 'f1-score': 0.8839298912469644, 'support': 120.0}, 'weighted avg': {'precision': 0.8897278114737439, 'recall': 0.8833333333333333, 'f1-score': 0.8841640270298806, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'rbf'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.6349206349206349, 'recall': 0.975609756097561, 'f1-score': 0.7692307692307693, 'support': 41.0}, '1': {'precision': 0.8333333333333334, 'recall': 0.4166666666666667, 'f1-score': 0.5555555555555556, 'support': 36.0}, '2': {'precision': 0.8461538461538461, 'recall': 0.7674418604651163, 'f1-score': 0.8048780487804879, 'support': 43.0}, 'accuracy': 0.7333333333333333, 'macro avg': {'precision': 0.7714692714692716, 'recall': 0.7199060944097813, 'f1-score': 0.709888124522271, 'support': 120.0}, 'weighted avg': {'precision': 0.7701363451363451, 'recall': 0.7333333333333333, 'f1-score': 0.7179018136335209, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.73\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9310344827586207, 'recall': 0.6585365853658537, 'f1-score': 0.7714285714285715, 'support': 41.0}, '1': {'precision': 0.6956521739130435, 'recall': 0.8888888888888888, 'f1-score': 0.7804878048780488, 'support': 36.0}, '2': {'precision': 0.8888888888888888, 'recall': 0.9302325581395349, 'f1-score': 0.9090909090909091, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8385251818535177, 'recall': 0.8258860107980924, 'f1-score': 0.8203357617991766, 'support': 120.0}, 'weighted avg': {'precision': 0.8453176189682935, 'recall': 0.825, 'f1-score': 0.823475345792419, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'alpha': 0.1}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.926829268292683, 'f1-score': 0.8941176470588236, 'support': 41.0}, '1': {'precision': 0.8888888888888888, 'recall': 0.8888888888888888, 'f1-score': 0.8888888888888888, 'support': 36.0}, '2': {'precision': 0.95, 'recall': 0.8837209302325582, 'f1-score': 0.9156626506024096, 'support': 43.0}, 'accuracy': 0.9, 'macro avg': {'precision': 0.9008417508417509, 'recall': 0.8998130291380434, 'f1-score': 0.8995563955167073, 'support': 120.0}, 'weighted avg': {'precision': 0.9021590909090909, 'recall': 0.9, 'f1-score': 0.9002693125442948, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.90\n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8636363636363636, 'recall': 0.926829268292683, 'f1-score': 0.8941176470588236, 'support': 41.0}, '1': {'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1-score': 0.9166666666666666, 'support': 36.0}, '2': {'precision': 0.95, 'recall': 0.8837209302325582, 'f1-score': 0.9156626506024096, 'support': 43.0}, 'accuracy': 0.9083333333333333, 'macro avg': {'precision': 0.9101010101010102, 'recall': 0.9090722883973026, 'f1-score': 0.9088156547759666, 'support': 120.0}, 'weighted avg': {'precision': 0.9104924242424242, 'recall': 0.9083333333333333, 'f1-score': 0.9086026458776282, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.91\n",
      "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_chi2_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7090909090909091, 'recall': 0.9512195121951219, 'f1-score': 0.8125, 'support': 41.0}, '1': {'precision': 0.9333333333333333, 'recall': 0.7777777777777778, 'f1-score': 0.8484848484848485, 'support': 36.0}, '2': {'precision': 0.9142857142857143, 'recall': 0.7441860465116279, 'f1-score': 0.8205128205128205, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8522366522366522, 'recall': 0.8243944454948425, 'f1-score': 0.8271658896658897, 'support': 120.0}, 'weighted avg': {'precision': 0.8498917748917748, 'recall': 0.825, 'f1-score': 0.8261667152292153, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 300}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8181818181818182, 'recall': 0.8780487804878049, 'f1-score': 0.8470588235294118, 'support': 41.0}, '1': {'precision': 0.8857142857142857, 'recall': 0.8611111111111112, 'f1-score': 0.8732394366197183, 'support': 36.0}, '2': {'precision': 0.926829268292683, 'recall': 0.8837209302325582, 'f1-score': 0.9047619047619048, 'support': 43.0}, 'accuracy': 0.875, 'macro avg': {'precision': 0.8769084573962623, 'recall': 0.8742936072771581, 'f1-score': 0.8750200549703449, 'support': 120.0}, 'weighted avg': {'precision': 0.8773735613979518, 'recall': 0.875, 'f1-score': 0.8755899448981469, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 100.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.7872340425531915, 'recall': 0.9024390243902439, 'f1-score': 0.8409090909090909, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.9024390243902439, 'recall': 0.8604651162790697, 'f1-score': 0.8809523809523809, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8653076889811451, 'recall': 0.8561532320749565, 'f1-score': 0.8582675494440201, 'support': 120.0}, 'weighted avg': {'precision': 0.8642206149455113, 'recall': 0.8583333333333333, 'f1-score': 0.8588675621763857, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7058823529411765, 'recall': 0.8780487804878049, 'f1-score': 0.782608695652174, 'support': 41.0}, '1': {'precision': 0.8275862068965517, 'recall': 0.6666666666666666, 'f1-score': 0.7384615384615385, 'support': 36.0}, '2': {'precision': 0.85, 'recall': 0.7906976744186046, 'f1-score': 0.8192771084337349, 'support': 43.0}, 'accuracy': 0.7833333333333333, 'macro avg': {'precision': 0.7944895199459094, 'recall': 0.7784710405243587, 'f1-score': 0.7801157808491491, 'support': 120.0}, 'weighted avg': {'precision': 0.7940356659905341, 'recall': 0.7833333333333333, 'f1-score': 0.7825040630750427, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.75, 'recall': 0.5853658536585366, 'f1-score': 0.6575342465753424, 'support': 41.0}, '1': {'precision': 0.6666666666666666, 'recall': 0.8888888888888888, 'f1-score': 0.7619047619047619, 'support': 36.0}, '2': {'precision': 0.875, 'recall': 0.813953488372093, 'f1-score': 0.8433734939759037, 'support': 43.0}, 'accuracy': 0.7583333333333333, 'macro avg': {'precision': 0.7638888888888888, 'recall': 0.7627360769731729, 'f1-score': 0.7542708341520026, 'support': 120.0}, 'weighted avg': {'precision': 0.7697916666666667, 'recall': 0.7583333333333333, 'f1-score': 0.7554377981593693, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.76\n",
      "{'alpha': 2.0}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.7777777777777778, 'recall': 0.8536585365853658, 'f1-score': 0.813953488372093, 'support': 41.0}, '1': {'precision': 0.8285714285714286, 'recall': 0.8055555555555556, 'f1-score': 0.8169014084507042, 'support': 36.0}, '2': {'precision': 0.875, 'recall': 0.813953488372093, 'f1-score': 0.8433734939759037, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8271164021164021, 'recall': 0.8243891935043383, 'f1-score': 0.8247427969329003, 'support': 120.0}, 'weighted avg': {'precision': 0.827853835978836, 'recall': 0.825, 'f1-score': 0.8253800330703752, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50, 25)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.7916666666666666, 'recall': 0.926829268292683, 'f1-score': 0.8539325842696629, 'support': 41.0}, '1': {'precision': 0.9090909090909091, 'recall': 0.8333333333333334, 'f1-score': 0.8695652173913043, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8746114996114995, 'recall': 0.8657906346505326, 'f1-score': 0.8671821940495907, 'support': 120.0}, 'weighted avg': {'precision': 0.8739826146076146, 'recall': 0.8666666666666667, 'f1-score': 0.867264011184323, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'alpha': 0.01, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_400.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.6964285714285714, 'recall': 0.9512195121951219, 'f1-score': 0.8041237113402062, 'support': 41.0}, '1': {'precision': 0.9310344827586207, 'recall': 0.75, 'f1-score': 0.8307692307692308, 'support': 36.0}, '2': {'precision': 0.9142857142857143, 'recall': 0.7441860465116279, 'f1-score': 0.8205128205128205, 'support': 43.0}, 'accuracy': 0.8166666666666667, 'macro avg': {'precision': 0.8472495894909687, 'recall': 0.8151351862355832, 'f1-score': 0.8184685875407526, 'support': 120.0}, 'weighted avg': {'precision': 0.8448758210180624, 'recall': 0.8166666666666667, 'f1-score': 0.8179901312891004, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.7755102040816326, 'recall': 0.926829268292683, 'f1-score': 0.8444444444444444, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8682790423861851, 'recall': 0.8565313753912734, 'f1-score': 0.8584781338009458, 'support': 120.0}, 'weighted avg': {'precision': 0.8676102171637886, 'recall': 0.8583333333333333, 'f1-score': 0.8590350178011583, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'C': 10.0, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8085106382978723, 'recall': 0.926829268292683, 'f1-score': 0.8636363636363636, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.9024390243902439, 'recall': 0.8604651162790697, 'f1-score': 0.8809523809523809, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8723998875627054, 'recall': 0.8642833133757696, 'f1-score': 0.8658433070197775, 'support': 120.0}, 'weighted avg': {'precision': 0.8714901184916104, 'recall': 0.8666666666666667, 'f1-score': 0.8666327136915372, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'C': 1, 'decision_function_shape': 'ovr', 'kernel': 'sigmoid'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.7058823529411765, 'recall': 0.8780487804878049, 'f1-score': 0.782608695652174, 'support': 41.0}, '1': {'precision': 0.6944444444444444, 'recall': 0.6944444444444444, 'f1-score': 0.6944444444444444, 'support': 36.0}, '2': {'precision': 0.8787878787878788, 'recall': 0.6744186046511628, 'f1-score': 0.7631578947368421, 'support': 43.0}, 'accuracy': 0.75, 'macro avg': {'precision': 0.7597048920578332, 'recall': 0.7489706098611374, 'f1-score': 0.7467370116111535, 'support': 120.0}, 'weighted avg': {'precision': 0.7644087938205585, 'recall': 0.75, 'f1-score': 0.7491895499618612, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.75\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.7741935483870968, 'recall': 0.5853658536585366, 'f1-score': 0.6666666666666666, 'support': 41.0}, '1': {'precision': 0.6875, 'recall': 0.9166666666666666, 'f1-score': 0.7857142857142857, 'support': 36.0}, '2': {'precision': 0.8780487804878049, 'recall': 0.8372093023255814, 'f1-score': 0.8571428571428571, 'support': 43.0}, 'accuracy': 0.775, 'macro avg': {'precision': 0.7799141096249672, 'recall': 0.7797472742169282, 'f1-score': 0.7698412698412698, 'support': 120.0}, 'weighted avg': {'precision': 0.7854002753737215, 'recall': 0.775, 'f1-score': 0.7706349206349207, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.78\n",
      "{'alpha': 2.0}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.78, 'recall': 0.9512195121951219, 'f1-score': 0.8571428571428571, 'support': 41.0}, '1': {'precision': 0.8484848484848485, 'recall': 0.7777777777777778, 'f1-score': 0.8115942028985508, 'support': 36.0}, '2': {'precision': 0.9459459459459459, 'recall': 0.813953488372093, 'f1-score': 0.875, 'support': 43.0}, 'accuracy': 0.85, 'macro avg': {'precision': 0.8581435981435982, 'recall': 0.847650259448331, 'f1-score': 0.847912353347136, 'support': 120.0}, 'weighted avg': {'precision': 0.8600094185094186, 'recall': 0.85, 'f1-score': 0.8498770703933747, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.85\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.7551020408163265, 'recall': 0.9024390243902439, 'f1-score': 0.8222222222222222, 'support': 41.0}, '1': {'precision': 0.875, 'recall': 0.7777777777777778, 'f1-score': 0.8235294117647058, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8510596546310832, 'recall': 0.839142034831201, 'f1-score': 0.8412668048249109, 'support': 120.0}, 'weighted avg': {'precision': 0.8512624280481423, 'recall': 0.8416666666666667, 'f1-score': 0.8426188957968012, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_800.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7272727272727273, 'recall': 0.975609756097561, 'f1-score': 0.8333333333333334, 'support': 41.0}, '1': {'precision': 0.90625, 'recall': 0.8055555555555556, 'f1-score': 0.8529411764705882, 'support': 36.0}, '2': {'precision': 0.9393939393939394, 'recall': 0.7209302325581395, 'f1-score': 0.8157894736842105, 'support': 43.0}, 'accuracy': 0.8333333333333334, 'macro avg': {'precision': 0.857638888888889, 'recall': 0.8340318480704187, 'f1-score': 0.8340213278293773, 'support': 120.0}, 'weighted avg': {'precision': 0.8569760101010101, 'recall': 0.8333333333333334, 'f1-score': 0.8329291365669075, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.83\n",
      "{'max_depth': 30, 'max_features': 'log2', 'n_estimators': 200}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8260869565217391, 'recall': 0.926829268292683, 'f1-score': 0.8735632183908046, 'support': 41.0}, '1': {'precision': 0.8857142857142857, 'recall': 0.8611111111111112, 'f1-score': 0.8732394366197183, 'support': 36.0}, '2': {'precision': 0.9230769230769231, 'recall': 0.8372093023255814, 'f1-score': 0.8780487804878049, 'support': 43.0}, 'accuracy': 0.875, 'macro avg': {'precision': 0.8782927217709826, 'recall': 0.8750498939097918, 'f1-score': 0.8749504784994425, 'support': 120.0}, 'weighted avg': {'precision': 0.8787298932951106, 'recall': 0.875, 'f1-score': 0.8750734102775705, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.88\n",
      "{'C': 1.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.6521739130434783, 'recall': 0.7317073170731707, 'f1-score': 0.6896551724137931, 'support': 41.0}, '1': {'precision': 0.7352941176470589, 'recall': 0.6944444444444444, 'f1-score': 0.7142857142857143, 'support': 36.0}, '2': {'precision': 0.9, 'recall': 0.8372093023255814, 'f1-score': 0.8674698795180723, 'support': 43.0}, 'accuracy': 0.7583333333333333, 'macro avg': {'precision': 0.7624893435635124, 'recall': 0.7544536879477323, 'f1-score': 0.7571369220725267, 'support': 120.0}, 'weighted avg': {'precision': 0.7659143222506394, 'recall': 0.7583333333333333, 'f1-score': 0.7607612716877362, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.76\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'rbf'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.6938775510204082, 'recall': 0.8292682926829268, 'f1-score': 0.7555555555555555, 'support': 41.0}, '1': {'precision': 0.6875, 'recall': 0.6111111111111112, 'f1-score': 0.6470588235294118, 'support': 36.0}, '2': {'precision': 0.7692307692307693, 'recall': 0.6976744186046512, 'f1-score': 0.7317073170731707, 'support': 43.0}, 'accuracy': 0.7166666666666667, 'macro avg': {'precision': 0.7168694400837258, 'recall': 0.7126846074662296, 'f1-score': 0.711440565386046, 'support': 120.0}, 'weighted avg': {'precision': 0.7189658555729984, 'recall': 0.7166666666666667, 'f1-score': 0.7144609171581913, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.72\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9655172413793104, 'recall': 0.6829268292682927, 'f1-score': 0.8, 'support': 41.0}, '1': {'precision': 0.6875, 'recall': 0.9166666666666666, 'f1-score': 0.7857142857142857, 'support': 36.0}, '2': {'precision': 0.8837209302325582, 'recall': 0.8837209302325582, 'f1-score': 0.8837209302325582, 'support': 43.0}, 'accuracy': 0.825, 'macro avg': {'precision': 0.8455793905372895, 'recall': 0.8277714753891724, 'f1-score': 0.8231450719822814, 'support': 120.0}, 'weighted avg': {'precision': 0.852801724137931, 'recall': 0.825, 'f1-score': 0.8257142857142857, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'alpha': 0.5}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8108108108108109, 'recall': 0.7317073170731707, 'f1-score': 0.7692307692307693, 'support': 41.0}, '1': {'precision': 0.7111111111111111, 'recall': 0.8888888888888888, 'f1-score': 0.7901234567901234, 'support': 36.0}, '2': {'precision': 0.9473684210526315, 'recall': 0.8372093023255814, 'f1-score': 0.8888888888888888, 'support': 43.0}, 'accuracy': 0.8166666666666667, 'macro avg': {'precision': 0.8230967809915178, 'recall': 0.8192685027625469, 'f1-score': 0.8160810383032605, 'support': 120.0}, 'weighted avg': {'precision': 0.8298340445708867, 'recall': 0.8166666666666667, 'f1-score': 0.8183760683760684, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,)}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.76, 'recall': 0.926829268292683, 'f1-score': 0.8351648351648352, 'support': 41.0}, '1': {'precision': 0.896551724137931, 'recall': 0.7222222222222222, 'f1-score': 0.8, 'support': 36.0}, '2': {'precision': 0.9024390243902439, 'recall': 0.8604651162790697, 'f1-score': 0.8809523809523809, 'support': 43.0}, 'accuracy': 0.8416666666666667, 'macro avg': {'precision': 0.8529969161760583, 'recall': 0.8365055355979916, 'f1-score': 0.8387057387057387, 'support': 120.0}, 'weighted avg': {'precision': 0.8520061676478835, 'recall': 0.8416666666666667, 'f1-score': 0.8410225885225885, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.84\n",
      "{'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'}\n",
      "Combined classification report saved as 'combined_classification_report_mi_1200.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: random_forest\n",
      "{'0': {'precision': 0.7547169811320755, 'recall': 0.975609756097561, 'f1-score': 0.851063829787234, 'support': 41.0}, '1': {'precision': 0.9354838709677419, 'recall': 0.8055555555555556, 'f1-score': 0.8656716417910447, 'support': 36.0}, '2': {'precision': 0.9444444444444444, 'recall': 0.7906976744186046, 'f1-score': 0.8607594936708861, 'support': 43.0}, 'accuracy': 0.8583333333333333, 'macro avg': {'precision': 0.8782150988480873, 'recall': 0.857287662023907, 'f1-score': 0.8591649884163882, 'support': 120.0}, 'weighted avg': {'precision': 0.8769327224363742, 'recall': 0.8583333333333333, 'f1-score': 0.858920452946686, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.86\n",
      "{'max_depth': 20, 'max_features': 'log2', 'n_estimators': 300}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: logistic_regression\n",
      "{'0': {'precision': 0.8260869565217391, 'recall': 0.926829268292683, 'f1-score': 0.8735632183908046, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.9487179487179487, 'recall': 0.8604651162790697, 'f1-score': 0.9024390243902439, 'support': 43.0}, 'accuracy': 0.8916666666666667, 'macro avg': {'precision': 0.8963635398418006, 'recall': 0.8920610911535473, 'f1-score': 0.8924702311617579, 'support': 120.0}, 'weighted avg': {'precision': 0.8964893560545735, 'recall': 0.8916666666666667, 'f1-score': 0.8922639519012966, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.89\n",
      "{'C': 10.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: svm_classifier\n",
      "{'0': {'precision': 0.8571428571428571, 'recall': 0.8780487804878049, 'f1-score': 0.8674698795180723, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.9069767441860465, 'recall': 0.9069767441860465, 'f1-score': 0.9069767441860465, 'support': 43.0}, 'accuracy': 0.8916666666666667, 'macro avg': {'precision': 0.8928017718715392, 'recall': 0.8913048045209133, 'f1-score': 0.8919516914694481, 'support': 120.0}, 'weighted avg': {'precision': 0.8921428571428571, 'recall': 0.8916666666666667, 'f1-score': 0.8918080773799423, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.89\n",
      "{'C': 10, 'decision_function_shape': 'ovr', 'kernel': 'linear'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: decision_tree\n",
      "{'0': {'precision': 0.723404255319149, 'recall': 0.8292682926829268, 'f1-score': 0.7727272727272727, 'support': 41.0}, '1': {'precision': 0.8064516129032258, 'recall': 0.6944444444444444, 'f1-score': 0.746268656716418, 'support': 36.0}, '2': {'precision': 0.7857142857142857, 'recall': 0.7674418604651163, 'f1-score': 0.7764705882352941, 'support': 43.0}, 'accuracy': 0.7666666666666667, 'macro avg': {'precision': 0.7718567179788868, 'recall': 0.7637181991974958, 'f1-score': 0.765155505892995, 'support': 120.0}, 'weighted avg': {'precision': 0.7706462234859627, 'recall': 0.7666666666666667, 'f1-score': 0.7661310426477239, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.77\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: nb_classifier\n",
      "{'0': {'precision': 0.9310344827586207, 'recall': 0.6585365853658537, 'f1-score': 0.7714285714285715, 'support': 41.0}, '1': {'precision': 0.7380952380952381, 'recall': 0.8611111111111112, 'f1-score': 0.7948717948717948, 'support': 36.0}, '2': {'precision': 0.8163265306122449, 'recall': 0.9302325581395349, 'f1-score': 0.8695652173913043, 'support': 43.0}, 'accuracy': 0.8166666666666667, 'macro avg': {'precision': 0.8284854171553678, 'recall': 0.8166267515388332, 'f1-score': 0.8119551945638902, 'support': 120.0}, 'weighted avg': {'precision': 0.8320490265071546, 'recall': 0.8166666666666667, 'f1-score': 0.8136271699315178, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.82\n",
      "{'alpha': 0.5}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: mlp_classifier\n",
      "{'0': {'precision': 0.8604651162790697, 'recall': 0.9024390243902439, 'f1-score': 0.8809523809523809, 'support': 41.0}, '1': {'precision': 0.8823529411764706, 'recall': 0.8333333333333334, 'f1-score': 0.8571428571428571, 'support': 36.0}, '2': {'precision': 0.8604651162790697, 'recall': 0.8604651162790697, 'f1-score': 0.8604651162790697, 'support': 43.0}, 'accuracy': 0.8666666666666667, 'macro avg': {'precision': 0.8677610579115367, 'recall': 0.8654124913342157, 'f1-score': 0.8661867847914358, 'support': 120.0}, 'weighted avg': {'precision': 0.8670314637482901, 'recall': 0.8666666666666667, 'f1-score': 0.866468253968254, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.87\n",
      "{'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50, 25)}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification for model: SGD_classifier\n",
      "{'0': {'precision': 0.8409090909090909, 'recall': 0.9024390243902439, 'f1-score': 0.8705882352941177, 'support': 41.0}, '1': {'precision': 0.9142857142857143, 'recall': 0.8888888888888888, 'f1-score': 0.9014084507042254, 'support': 36.0}, '2': {'precision': 0.926829268292683, 'recall': 0.8837209302325582, 'f1-score': 0.9047619047619048, 'support': 43.0}, 'accuracy': 0.8916666666666667, 'macro avg': {'precision': 0.8940080244958294, 'recall': 0.8916829478372303, 'f1-score': 0.8922528635867493, 'support': 120.0}, 'weighted avg': {'precision': 0.8937101414845317, 'recall': 0.8916666666666667, 'f1-score': 0.8920798648097736, 'support': 120.0}}\n",
      "Test Set Accuracy: 0.89\n",
      "{'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'}\n",
      "Combined classification report saved as 'combined_classification_report_uni.csv'\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, train_set_key in enumerate(train_set):\n",
    "  reports = []\n",
    "  for classifier in classifier_properties:\n",
    "    print(f\"Classification for model: {classifier}\")\n",
    "    classify(feature_name=train_set_key,\n",
    "             classifier=classifier_properties[classifier],\n",
    "             x_train=train_set.get(train_set_key)[\"train\"],\n",
    "             y_train=y_train,\n",
    "             x_test=train_set.get(train_set_key)[\"test\"],\n",
    "             y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y8lV-Jt99EH7",
   "metadata": {
    "id": "y8lV-Jt99EH7"
   },
   "source": [
    "Loading all classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "Oi2oYj0bIwOm",
   "metadata": {
    "id": "Oi2oYj0bIwOm"
   },
   "outputs": [],
   "source": [
    "report_chi2_400 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_400.csv\")\n",
    "report_chi2_800 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_800.csv\")\n",
    "report_chi2_1200 = pd.read_csv(\"C:\\Results\\combined_classification_report_chi2_1200.csv\")\n",
    "\n",
    "report_mi_400 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_400.csv\")\n",
    "report_mi_800 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_800.csv\")\n",
    "report_mi_1200 = pd.read_csv(\"C:\\Results\\combined_classification_report_mi_1200.csv\")\n",
    "\n",
    "report_uni = pd.read_csv(\"C:\\Results\\combined_classification_report_uni.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "RPBhF16itQll",
   "metadata": {
    "id": "RPBhF16itQll"
   },
   "outputs": [],
   "source": [
    "def prepare_report(df, feature_selection_tag):\n",
    "    df = df[['classifier', 'accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score', 'best_params']]\n",
    "    # Add a new column with a fixed value indicating the feature selection method\n",
    "    df['Feature Selection'] = [feature_selection_tag] * len(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "v0TVyC4FpTih",
   "metadata": {
    "id": "v0TVyC4FpTih"
   },
   "outputs": [],
   "source": [
    "report_chi2_400 = prepare_report(report_chi2_400, 'chi2_400')\n",
    "report_chi2_800 = prepare_report(report_chi2_800, 'chi2_800')\n",
    "report_chi2_1200 = prepare_report(report_chi2_1200, 'chi2_1200')\n",
    "\n",
    "report_mi_400 = prepare_report(report_mi_400, 'mi_400')\n",
    "report_mi_800 = prepare_report(report_mi_800, 'mi_800')\n",
    "report_mi_1200 = prepare_report(report_mi_1200, 'mi_1200')\n",
    "\n",
    "report_uni = prepare_report(report_uni, 'All features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "Ndn6unaFdbC7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Ndn6unaFdbC7",
    "outputId": "79d9da08-4a51-4ed6-c005-f2461f0042d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.839</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.883</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'ovr', 'penalty': ...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.883</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.792</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.723</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.842</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.883</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'squared_hinge', 'pen...</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.857</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.917</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'ovr', 'penalty': ...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.858</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.767</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.795</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.898</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'squared_hinge', 'pen...</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.864</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.901</td>\n",
       "      <td>{'C': 10.0, 'multi_class': 'multinomial', 'pen...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.884</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.710</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.820</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'modified_huber', 'pe...</td>\n",
       "      <td>chi2_1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0   RandomForestClassifier     0.842                0.885             0.835   \n",
       "1       LogisticRegression     0.883                0.892             0.882   \n",
       "2                      SVC     0.883                0.895             0.882   \n",
       "3   DecisionTreeClassifier     0.792                0.814             0.788   \n",
       "4            MultinomialNB     0.733                0.774             0.739   \n",
       "5            MLPClassifier     0.842                0.849             0.841   \n",
       "6            SGDClassifier     0.883                0.895             0.882   \n",
       "7   RandomForestClassifier     0.858                0.889             0.853   \n",
       "8       LogisticRegression     0.917                0.920             0.917   \n",
       "9                      SVC     0.858                0.865             0.857   \n",
       "10  DecisionTreeClassifier     0.775                0.813             0.766   \n",
       "11           MultinomialNB     0.800                0.812             0.801   \n",
       "12           MLPClassifier     0.900                0.901             0.897   \n",
       "13           SGDClassifier     0.925                0.927             0.925   \n",
       "14  RandomForestClassifier     0.867                0.881             0.862   \n",
       "15      LogisticRegression     0.900                0.903             0.901   \n",
       "16                     SVC     0.883                0.890             0.883   \n",
       "17  DecisionTreeClassifier     0.733                0.771             0.720   \n",
       "18           MultinomialNB     0.825                0.839             0.826   \n",
       "19           MLPClassifier     0.900                0.901             0.900   \n",
       "20           SGDClassifier     0.908                0.910             0.909   \n",
       "\n",
       "    macro avg_f1-score                                        best_params  \\\n",
       "0                0.839  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "1                0.883  {'C': 100.0, 'multi_class': 'ovr', 'penalty': ...   \n",
       "2                0.883  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "3                0.792  {'criterion': 'entropy', 'max_depth': None, 'm...   \n",
       "4                0.723                                     {'alpha': 0.1}   \n",
       "5                0.842  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
       "6                0.883  {'alpha': 0.001, 'loss': 'squared_hinge', 'pen...   \n",
       "7                0.857  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "8                0.917  {'C': 100.0, 'multi_class': 'ovr', 'penalty': ...   \n",
       "9                0.858  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "10               0.767  {'criterion': 'entropy', 'max_depth': None, 'm...   \n",
       "11               0.795                                     {'alpha': 0.1}   \n",
       "12               0.898  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "13               0.925  {'alpha': 0.001, 'loss': 'squared_hinge', 'pen...   \n",
       "14               0.864  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "15               0.901  {'C': 10.0, 'multi_class': 'multinomial', 'pen...   \n",
       "16               0.884  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "17               0.710  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "18               0.820                                     {'alpha': 0.1}   \n",
       "19               0.900  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...   \n",
       "20               0.909  {'alpha': 0.001, 'loss': 'modified_huber', 'pe...   \n",
       "\n",
       "   Feature Selection  \n",
       "0           chi2_400  \n",
       "1           chi2_400  \n",
       "2           chi2_400  \n",
       "3           chi2_400  \n",
       "4           chi2_400  \n",
       "5           chi2_400  \n",
       "6           chi2_400  \n",
       "7           chi2_800  \n",
       "8           chi2_800  \n",
       "9           chi2_800  \n",
       "10          chi2_800  \n",
       "11          chi2_800  \n",
       "12          chi2_800  \n",
       "13          chi2_800  \n",
       "14         chi2_1200  \n",
       "15         chi2_1200  \n",
       "16         chi2_1200  \n",
       "17         chi2_1200  \n",
       "18         chi2_1200  \n",
       "19         chi2_1200  \n",
       "20         chi2_1200  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_chi2_400 = pd.DataFrame(report_chi2_400)\n",
    "df_report_chi2_800 = pd.DataFrame(report_chi2_800)\n",
    "df_report_chi2_1200 = pd.DataFrame(report_chi2_1200)\n",
    "\n",
    "merge_df_chi2 = pd.concat([df_report_chi2_400,df_report_chi2_800,df_report_chi2_1200], axis=0)\n",
    "merge_df_chi2.reset_index(drop=True, inplace=True)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "merge_df_chi2[columns_to_round] = merge_df_chi2[columns_to_round].apply(lambda x: round(x, 3))\n",
    "merge_df_chi2.to_csv(r'C:\\results\\report_chi2.csv', index=False)\n",
    "merge_df_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "tl01bFLTqr8v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "tl01bFLTqr8v",
    "outputId": "3744f4ec-fd16-4efd-b57d-c5c8624190f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.827</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.875</td>\n",
       "      <td>{'C': 100.0, 'multi_class': 'ovr', 'penalty': ...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.858</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.780</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.754</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.825</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.867</td>\n",
       "      <td>{'alpha': 0.01, 'loss': 'modified_huber', 'pen...</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.818</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.858</td>\n",
       "      <td>{'C': 10.0, 'multi_class': 'ovr', 'penalty': '...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'C': 1, 'decision_function_shape': 'ovr', 'ke...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.747</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.770</td>\n",
       "      <td>{'alpha': 2.0}</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.848</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.841</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>mi_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.834</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>{'C': 1.0, 'multi_class': 'multinomial', 'pena...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.757</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.823</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.816</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.839</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0   RandomForestClassifier     0.825                0.852             0.824   \n",
       "1       LogisticRegression     0.875                0.877             0.874   \n",
       "2                      SVC     0.858                0.865             0.856   \n",
       "3   DecisionTreeClassifier     0.783                0.794             0.778   \n",
       "4            MultinomialNB     0.758                0.764             0.763   \n",
       "5            MLPClassifier     0.825                0.827             0.824   \n",
       "6            SGDClassifier     0.867                0.875             0.866   \n",
       "7   RandomForestClassifier     0.817                0.847             0.815   \n",
       "8       LogisticRegression     0.858                0.868             0.857   \n",
       "9                      SVC     0.867                0.872             0.864   \n",
       "10  DecisionTreeClassifier     0.750                0.760             0.749   \n",
       "11           MultinomialNB     0.775                0.780             0.780   \n",
       "12           MLPClassifier     0.850                0.858             0.848   \n",
       "13           SGDClassifier     0.842                0.851             0.839   \n",
       "14  RandomForestClassifier     0.833                0.858             0.834   \n",
       "15      LogisticRegression     0.875                0.878             0.875   \n",
       "16                     SVC     0.758                0.762             0.754   \n",
       "17  DecisionTreeClassifier     0.717                0.717             0.713   \n",
       "18           MultinomialNB     0.825                0.846             0.828   \n",
       "19           MLPClassifier     0.817                0.823             0.819   \n",
       "20           SGDClassifier     0.842                0.853             0.837   \n",
       "\n",
       "    macro avg_f1-score                                        best_params  \\\n",
       "0                0.827  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "1                0.875  {'C': 100.0, 'multi_class': 'ovr', 'penalty': ...   \n",
       "2                0.858  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "3                0.780  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "4                0.754                                     {'alpha': 2.0}   \n",
       "5                0.825  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...   \n",
       "6                0.867  {'alpha': 0.01, 'loss': 'modified_huber', 'pen...   \n",
       "7                0.818  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "8                0.858  {'C': 10.0, 'multi_class': 'ovr', 'penalty': '...   \n",
       "9                0.866  {'C': 1, 'decision_function_shape': 'ovr', 'ke...   \n",
       "10               0.747  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "11               0.770                                     {'alpha': 2.0}   \n",
       "12               0.848  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "13               0.841  {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...   \n",
       "14               0.834  {'max_depth': 30, 'max_features': 'log2', 'n_e...   \n",
       "15               0.875  {'C': 1.0, 'multi_class': 'multinomial', 'pena...   \n",
       "16               0.757  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "17               0.711  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "18               0.823                                     {'alpha': 0.5}   \n",
       "19               0.816  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "20               0.839  {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...   \n",
       "\n",
       "   Feature Selection  \n",
       "0             mi_400  \n",
       "1             mi_400  \n",
       "2             mi_400  \n",
       "3             mi_400  \n",
       "4             mi_400  \n",
       "5             mi_400  \n",
       "6             mi_400  \n",
       "7             mi_800  \n",
       "8             mi_800  \n",
       "9             mi_800  \n",
       "10            mi_800  \n",
       "11            mi_800  \n",
       "12            mi_800  \n",
       "13            mi_800  \n",
       "14           mi_1200  \n",
       "15           mi_1200  \n",
       "16           mi_1200  \n",
       "17           mi_1200  \n",
       "18           mi_1200  \n",
       "19           mi_1200  \n",
       "20           mi_1200  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mi_400 = pd.DataFrame(report_mi_400)\n",
    "df_report_mi_800 = pd.DataFrame(report_mi_800)\n",
    "df_report_mi_1200 = pd.DataFrame(report_mi_1200)\n",
    "\n",
    "merge_df_mi = pd.concat([df_report_mi_400,df_report_mi_800,df_report_mi_1200], axis=0)\n",
    "merge_df_mi.reset_index(drop=True, inplace=True)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "merge_df_mi[columns_to_round] = merge_df_mi[columns_to_round].apply(lambda x: round(x, 3))\n",
    "merge_df_mi.to_csv(r'C:\\results\\report_mi.csv', index=False)\n",
    "merge_df_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "VtkeF2NbQJol",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "VtkeF2NbQJol",
    "outputId": "2f856c68-6e93-44da-e4cb-b537ccb9f31f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.859</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.892</td>\n",
       "      <td>{'C': 10.0, 'multi_class': 'multinomial', 'pen...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.892</td>\n",
       "      <td>{'C': 10, 'decision_function_shape': 'ovr', 'k...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.765</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.812</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.866</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.892</td>\n",
       "      <td>{'alpha': 0.001, 'loss': 'hinge', 'penalty': '...</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               classifier  accuracy  macro avg_precision  macro avg_recall  \\\n",
       "0  RandomForestClassifier     0.858                0.878             0.857   \n",
       "1      LogisticRegression     0.892                0.896             0.892   \n",
       "2                     SVC     0.892                0.893             0.891   \n",
       "3  DecisionTreeClassifier     0.767                0.772             0.764   \n",
       "4           MultinomialNB     0.817                0.828             0.817   \n",
       "5           MLPClassifier     0.867                0.868             0.865   \n",
       "6           SGDClassifier     0.892                0.894             0.892   \n",
       "\n",
       "   macro avg_f1-score                                        best_params  \\\n",
       "0               0.859  {'max_depth': 20, 'max_features': 'log2', 'n_e...   \n",
       "1               0.892  {'C': 10.0, 'multi_class': 'multinomial', 'pen...   \n",
       "2               0.892  {'C': 10, 'decision_function_shape': 'ovr', 'k...   \n",
       "3               0.765  {'criterion': 'gini', 'max_depth': None, 'max_...   \n",
       "4               0.812                                     {'alpha': 0.5}   \n",
       "5               0.866  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...   \n",
       "6               0.892  {'alpha': 0.001, 'loss': 'hinge', 'penalty': '...   \n",
       "\n",
       "  Feature Selection  \n",
       "0      All features  \n",
       "1      All features  \n",
       "2      All features  \n",
       "3      All features  \n",
       "4      All features  \n",
       "5      All features  \n",
       "6      All features  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_uni = pd.DataFrame(report_uni)\n",
    "columns_to_round = ['accuracy', 'macro avg_precision', 'macro avg_recall', 'macro avg_f1-score']\n",
    "report_uni[columns_to_round] = report_uni[columns_to_round].apply(lambda x: round(x, 3))\n",
    "report_uni.to_csv(r'C:\\results\\report_uni.csv', index=False)\n",
    "report_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u2CvAH-tR3-O",
   "metadata": {
    "id": "u2CvAH-tR3-O"
   },
   "source": [
    "Finding maximum and minuímum accuracies in Chi2 & Mutual Info feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "V2mYAhF0j5dT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2mYAhF0j5dT",
    "outputId": "634472f8-0e21-4eba-83c0-d8dc9450e109"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Avg Precision</th>\n",
       "      <th>Macro Avg Recall</th>\n",
       "      <th>Feature Selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.925</td>\n",
       "      <td>chi2_800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.739</td>\n",
       "      <td>chi2_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.874</td>\n",
       "      <td>mi_400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.713</td>\n",
       "      <td>mi_1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.892</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.764</td>\n",
       "      <td>All features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy  Macro Avg Precision  Macro Avg Recall  \\\n",
       "0           SGDClassifier     0.925                0.927             0.925   \n",
       "1           MultinomialNB     0.733                0.774             0.739   \n",
       "2      LogisticRegression     0.875                0.877             0.874   \n",
       "3  DecisionTreeClassifier     0.717                0.717             0.713   \n",
       "4      LogisticRegression     0.892                0.896             0.892   \n",
       "5  DecisionTreeClassifier     0.767                0.772             0.764   \n",
       "\n",
       "  Feature Selection  \n",
       "0          chi2_800  \n",
       "1          chi2_400  \n",
       "2            mi_400  \n",
       "3           mi_1200  \n",
       "4      All features  \n",
       "5      All features  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy_details(df, feature_name):\n",
    "    # Finding index of max and min accuracies\n",
    "    max_accuracy_index = df['accuracy'].idxmax()\n",
    "    min_accuracy_index = df['accuracy'].idxmin()\n",
    "    \n",
    "    # Extracting details for maximum accuracy\n",
    "    max_details = {\n",
    "        'Classifier': df.loc[max_accuracy_index, 'classifier'],\n",
    "        'Type': 'Highest',\n",
    "        'Accuracy': df.loc[max_accuracy_index, 'accuracy'],\n",
    "        'Macro Avg Precision': df.loc[max_accuracy_index, 'macro avg_precision'],\n",
    "        'Macro Avg Recall': df.loc[max_accuracy_index, 'macro avg_recall'],\n",
    "        'Feature Selection': df.loc[max_accuracy_index, 'Feature Selection']\n",
    "    }\n",
    "    \n",
    "    # Extracting details for minimum accuracy\n",
    "    min_details = {\n",
    "        'Classifier': df.loc[min_accuracy_index, 'classifier'],\n",
    "        'Type': 'Lowest',\n",
    "        'Accuracy': df.loc[min_accuracy_index, 'accuracy'],\n",
    "        'Macro Avg Precision': df.loc[min_accuracy_index, 'macro avg_precision'],\n",
    "        'Macro Avg Recall': df.loc[min_accuracy_index, 'macro avg_recall'],\n",
    "        'Feature Selection': df.loc[min_accuracy_index, 'Feature Selection']\n",
    "    }\n",
    "    \n",
    "    # Creating DataFrame from details with specific column order\n",
    "    results_df = pd.DataFrame([max_details, min_details], columns=[\n",
    "        'Classifier', 'Accuracy', 'Macro Avg Precision', 'Macro Avg Recall', 'Feature Selection'\n",
    "    ])\n",
    "    return results_df\n",
    "\n",
    "# Using the function and combining results\n",
    "results_chi2 = get_accuracy_details(merge_df_chi2, 'Chi2')\n",
    "results_mi = get_accuracy_details(merge_df_mi, 'Mutual Information')\n",
    "results_uni = get_accuracy_details(report_uni, 'Unfiltered')\n",
    "\n",
    "# Combining all results into a single DataFrame\n",
    "final_results = pd.concat([results_chi2, results_mi, results_uni], ignore_index=True)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "xUCRGPRzq6Ws",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "xUCRGPRzq6Ws",
    "outputId": "17d39cfa-6f64-47d5-be69-75595c8445b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(final_results['Classifier'], final_results['Accuracy'], color='blue')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Machine Learning Classifiers')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "VCFcVIqUfXuR",
   "metadata": {
    "id": "VCFcVIqUfXuR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "def load_model(file_path):\n",
    "    \"\"\"Helper function to load a model from a specified file path.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Define model and selector file paths\n",
    "logistic_regression_path = \"C:/Results/LogisticRegression_chi2_800.pkl\"\n",
    "chi2_selector_path = \"C:/Results/Selectors/selector_chi2_800.pkl\"\n",
    "decision_tree_path = \"C:/Results/DecisionTreeClassifier_uni.pkl\"\n",
    "vectorizer_path = \"C:/Results/Selectors/selector_uni.pkl\"\n",
    "\n",
    "# Load models and selectors using the helper function\n",
    "logistic_regression = load_model(logistic_regression_path)\n",
    "chi2_selector = load_model(chi2_selector_path)\n",
    "decision_tree = load_model(decision_tree_path)\n",
    "vectorizer = load_model(vectorizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee36a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class with decision tree: 0 Neutral\n",
      "Predicted class with Logistic Regression: [2] Religious Offensive\n"
     ]
    }
   ],
   "source": [
    "# Process new text data\n",
    "new_text = [\"tum jeson ko to ddob kar majana chaye\"]\n",
    "test_vector = vectorizer.transform(new_text)\n",
    "new_data_transformed = chi2_selector.transform(test_vector)\n",
    "\n",
    "# Make predictions using the Logistic Regression and Decision Tree models\n",
    "prediction_lr = logistic_regression.predict(new_data_transformed)\n",
    "prediction_dt = decision_tree.predict(test_vector)\n",
    "\n",
    "# Define a function to print the decision tree prediction\n",
    "def print_decision_tree_prediction(prediction):\n",
    "    if prediction == 0:\n",
    "        print(\"Predicted class with decision tree: 0 Neutral\")\n",
    "    elif prediction == 1:\n",
    "        print(\"Predicted class with decision tree: 1 Political Offensive\")\n",
    "    else:\n",
    "        print(\"Predicted class with decision tree:\", prediction, \"Religious Offensive\")\n",
    "\n",
    "# Define a function to print the logistic regression prediction\n",
    "def print_logistic_regression_prediction(prediction):\n",
    "    if prediction == 0:\n",
    "        print(\"Predicted class with Logistic Regression: 0 Neutral\")\n",
    "    elif prediction == 1:\n",
    "        print(\"Predicted class with Logistic Regression: 1 Political Offensive\")\n",
    "    else:\n",
    "        print(\"Predicted class with Logistic Regression:\", prediction, \"Religious Offensive\")\n",
    "\n",
    "# Call the print functions to display predictions\n",
    "print_decision_tree_prediction(prediction_dt)\n",
    "print_logistic_regression_prediction(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6128fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
